24-Jan-24 07:26:36 - Test Speaker: M04
24-Jan-24 07:26:36 - Number of epochs: 20
24-Jan-24 07:26:36 - Log File Path: /output/logs/M04_20240124_072636.log

24-Jan-24 07:26:36 - Using GPU: Tesla T4

24-Jan-24 07:26:36 - Unique speakers found in the dataset:
24-Jan-24 07:26:36 - ['F01' 'F03' 'F04' 'FC01' 'FC02' 'FC03' 'M01' 'M02' 'M03' 'M04' 'M05'
 'MC01' 'MC02' 'MC03' 'MC04']

24-Jan-24 07:26:37 - After applying the text count threshold of 40, the number of data in each dataset is:
24-Jan-24 07:26:37 - Train:       10752/14667 (73%)
24-Jan-24 07:26:37 - Validation:  730/1075 (67%)
24-Jan-24 07:26:37 - Test:        442/652 (67%)

24-Jan-24 07:26:38 - Vocab Dictionary:
24-Jan-24 07:26:38 - {'[PAD]': 0, '<s>': 1, '</s>': 2, '[UNK]': 3, "'": 4, 'a': 5, 'b': 6, 'c': 7, 'd': 8, 'e': 9, 'f': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'n': 18, 'o': 19, 'p': 20, 'q': 21, 'r': 22, 's': 23, 't': 24, 'u': 25, 'v': 26, 'w': 27, 'x': 28, 'y': 29, 'z': 30, '|': 31}

24-Jan-24 07:27:22 - After filtering audio within a certain length, the number of data in each dataset is:
24-Jan-24 07:27:22 - Train:       10676/14667 (72%)
24-Jan-24 07:27:22 - Validation:  706/1075 (65%)
24-Jan-24 07:27:22 - Test:        369/652 (56%)

24-Jan-24 07:27:54 - Cloning https://huggingface.co/macarious/torgo_xlsr_finetune_M04 into local empty directory.
24-Jan-24 07:28:00 - Start Training
24-Jan-24 07:28:00 - Training Arguments:
24-Jan-24 07:28:00 - {'Training Epochs': 20, 'Training Batch Size': 4, 'Evaluation Batch Size': 4, 'Learning Rate': 0.0001, 'Weight Decay': 0.005}
24-Jan-24 07:28:00 - No checkpoint found in the repository. Training from scratch.
24-Jan-24 07:44:19 - Current Word Error Rate: 1.0
24-Jan-24 08:00:25 - Current Word Error Rate: 0.8221649484536082
24-Jan-24 08:16:20 - Current Word Error Rate: 0.615979381443299
24-Jan-24 08:32:21 - Current Word Error Rate: 0.5753865979381443
24-Jan-24 08:48:25 - Current Word Error Rate: 0.5277061855670103
24-Jan-24 09:04:40 - Current Word Error Rate: 0.41301546391752575
24-Jan-24 09:20:53 - Current Word Error Rate: 0.43105670103092786
24-Jan-24 09:37:00 - Current Word Error Rate: 0.37757731958762886
24-Jan-24 09:53:13 - Current Word Error Rate: 0.43170103092783507
24-Jan-24 10:09:19 - Current Word Error Rate: 0.38853092783505155
24-Jan-24 10:25:19 - Current Word Error Rate: 0.3337628865979381
24-Jan-24 10:41:19 - Current Word Error Rate: 0.3801546391752577
24-Jan-24 10:57:27 - Current Word Error Rate: 0.35631443298969073
24-Jan-24 11:13:45 - Current Word Error Rate: 0.3788659793814433
24-Jan-24 11:29:44 - Current Word Error Rate: 0.33505154639175255
24-Jan-24 11:45:48 - Current Word Error Rate: 0.32603092783505155
24-Jan-24 12:01:53 - Current Word Error Rate: 0.31958762886597936
24-Jan-24 12:18:15 - Current Word Error Rate: 0.3556701030927835
24-Jan-24 12:34:32 - Current Word Error Rate: 0.33054123711340205
24-Jan-24 12:50:54 - Current Word Error Rate: 0.29896907216494845
24-Jan-24 13:07:19 - Current Word Error Rate: 0.2957474226804124
24-Jan-24 13:23:48 - Current Word Error Rate: 0.30476804123711343
24-Jan-24 13:39:51 - Current Word Error Rate: 0.32667525773195877
24-Jan-24 13:55:56 - Current Word Error Rate: 0.30476804123711343
24-Jan-24 14:12:05 - Current Word Error Rate: 0.2970360824742268
24-Jan-24 14:28:15 - Current Word Error Rate: 0.29510309278350516
24-Jan-24 14:39:37 - Training completed in 7:11:37.205546

24-Jan-24 14:39:37 - Training Log Metrics:
24-Jan-24 14:39:37 - {'loss': 26.7638, 'learning_rate': 5e-05, 'epoch': 0.37, 'step': 500}

24-Jan-24 14:39:37 - {'loss': 3.5657, 'learning_rate': 0.0001, 'epoch': 0.75, 'step': 1000}

24-Jan-24 14:39:37 - {'eval_loss': 3.3393969535827637, 'eval_wer': 1.0, 'eval_runtime': 39.0671, 'eval_samples_per_second': 18.071, 'eval_steps_per_second': 4.531, 'epoch': 0.75, 'step': 1000}

24-Jan-24 14:39:37 - {'loss': 3.0775, 'learning_rate': 9.805295950155764e-05, 'epoch': 1.12, 'step': 1500}

24-Jan-24 14:39:37 - {'loss': 1.6728, 'learning_rate': 9.610591900311527e-05, 'epoch': 1.5, 'step': 2000}

24-Jan-24 14:39:37 - {'eval_loss': 2.0240085124969482, 'eval_wer': 0.8221649484536082, 'eval_runtime': 39.0569, 'eval_samples_per_second': 18.076, 'eval_steps_per_second': 4.532, 'epoch': 1.5, 'step': 2000}

24-Jan-24 14:39:37 - {'loss': 1.1075, 'learning_rate': 9.41588785046729e-05, 'epoch': 1.87, 'step': 2500}

24-Jan-24 14:39:37 - {'loss': 0.8728, 'learning_rate': 9.221183800623053e-05, 'epoch': 2.25, 'step': 3000}

24-Jan-24 14:39:37 - {'eval_loss': 1.6539386510849, 'eval_wer': 0.615979381443299, 'eval_runtime': 39.1397, 'eval_samples_per_second': 18.038, 'eval_steps_per_second': 4.522, 'epoch': 2.25, 'step': 3000}

24-Jan-24 14:39:37 - {'loss': 0.7405, 'learning_rate': 9.026479750778816e-05, 'epoch': 2.62, 'step': 3500}

24-Jan-24 14:39:37 - {'loss': 0.6675, 'learning_rate': 8.831775700934581e-05, 'epoch': 3.0, 'step': 4000}

24-Jan-24 14:39:37 - {'eval_loss': 1.6387226581573486, 'eval_wer': 0.5753865979381443, 'eval_runtime': 39.1883, 'eval_samples_per_second': 18.016, 'eval_steps_per_second': 4.517, 'epoch': 3.0, 'step': 4000}

24-Jan-24 14:39:37 - {'loss': 0.5725, 'learning_rate': 8.637071651090343e-05, 'epoch': 3.37, 'step': 4500}

24-Jan-24 14:39:37 - {'loss': 0.5636, 'learning_rate': 8.442367601246106e-05, 'epoch': 3.75, 'step': 5000}

24-Jan-24 14:39:37 - {'eval_loss': 1.6527141332626343, 'eval_wer': 0.5277061855670103, 'eval_runtime': 39.1198, 'eval_samples_per_second': 18.047, 'eval_steps_per_second': 4.525, 'epoch': 3.75, 'step': 5000}

24-Jan-24 14:39:37 - {'loss': 0.4866, 'learning_rate': 8.24766355140187e-05, 'epoch': 4.12, 'step': 5500}

24-Jan-24 14:39:37 - {'loss': 0.4598, 'learning_rate': 8.052959501557633e-05, 'epoch': 4.5, 'step': 6000}

24-Jan-24 14:39:37 - {'eval_loss': 1.638494849205017, 'eval_wer': 0.41301546391752575, 'eval_runtime': 39.0218, 'eval_samples_per_second': 18.092, 'eval_steps_per_second': 4.536, 'epoch': 4.5, 'step': 6000}

24-Jan-24 14:39:37 - {'loss': 0.4299, 'learning_rate': 7.858255451713395e-05, 'epoch': 4.87, 'step': 6500}

24-Jan-24 14:39:37 - {'loss': 0.3835, 'learning_rate': 7.663551401869158e-05, 'epoch': 5.25, 'step': 7000}

24-Jan-24 14:39:37 - {'eval_loss': 1.5931119918823242, 'eval_wer': 0.43105670103092786, 'eval_runtime': 39.175, 'eval_samples_per_second': 18.022, 'eval_steps_per_second': 4.518, 'epoch': 5.25, 'step': 7000}

24-Jan-24 14:39:37 - {'loss': 0.4063, 'learning_rate': 7.468847352024923e-05, 'epoch': 5.62, 'step': 7500}

24-Jan-24 14:39:37 - {'loss': 0.3881, 'learning_rate': 7.274143302180686e-05, 'epoch': 6.0, 'step': 8000}

24-Jan-24 14:39:37 - {'eval_loss': 1.1018757820129395, 'eval_wer': 0.37757731958762886, 'eval_runtime': 39.312, 'eval_samples_per_second': 17.959, 'eval_steps_per_second': 4.502, 'epoch': 6.0, 'step': 8000}

24-Jan-24 14:39:37 - {'loss': 0.339, 'learning_rate': 7.079439252336449e-05, 'epoch': 6.37, 'step': 8500}

24-Jan-24 14:39:37 - {'loss': 0.3276, 'learning_rate': 6.884735202492212e-05, 'epoch': 6.75, 'step': 9000}

24-Jan-24 14:39:37 - {'eval_loss': 1.4475901126861572, 'eval_wer': 0.43170103092783507, 'eval_runtime': 39.1836, 'eval_samples_per_second': 18.018, 'eval_steps_per_second': 4.517, 'epoch': 6.75, 'step': 9000}

24-Jan-24 14:39:37 - {'loss': 0.3331, 'learning_rate': 6.690031152647976e-05, 'epoch': 7.12, 'step': 9500}

24-Jan-24 14:39:37 - {'loss': 0.3099, 'learning_rate': 6.495327102803739e-05, 'epoch': 7.5, 'step': 10000}

24-Jan-24 14:39:37 - {'eval_loss': 1.560742735862732, 'eval_wer': 0.38853092783505155, 'eval_runtime': 39.5577, 'eval_samples_per_second': 17.847, 'eval_steps_per_second': 4.474, 'epoch': 7.5, 'step': 10000}

24-Jan-24 14:39:37 - {'loss': 0.3051, 'learning_rate': 6.300623052959502e-05, 'epoch': 7.87, 'step': 10500}

24-Jan-24 14:39:37 - {'loss': 0.2973, 'learning_rate': 6.105919003115265e-05, 'epoch': 8.25, 'step': 11000}

24-Jan-24 14:39:37 - {'eval_loss': 1.542093276977539, 'eval_wer': 0.3337628865979381, 'eval_runtime': 39.4637, 'eval_samples_per_second': 17.89, 'eval_steps_per_second': 4.485, 'epoch': 8.25, 'step': 11000}

24-Jan-24 14:39:37 - {'loss': 0.2837, 'learning_rate': 5.911214953271028e-05, 'epoch': 8.62, 'step': 11500}

24-Jan-24 14:39:37 - {'loss': 0.2961, 'learning_rate': 5.7165109034267914e-05, 'epoch': 9.0, 'step': 12000}

24-Jan-24 14:39:37 - {'eval_loss': 1.6223794221878052, 'eval_wer': 0.3801546391752577, 'eval_runtime': 39.2337, 'eval_samples_per_second': 17.995, 'eval_steps_per_second': 4.511, 'epoch': 9.0, 'step': 12000}

24-Jan-24 14:39:37 - {'loss': 0.2664, 'learning_rate': 5.521806853582555e-05, 'epoch': 9.37, 'step': 12500}

24-Jan-24 14:39:37 - {'loss': 0.2702, 'learning_rate': 5.327102803738318e-05, 'epoch': 9.74, 'step': 13000}

24-Jan-24 14:39:37 - {'eval_loss': 1.9051119089126587, 'eval_wer': 0.35631443298969073, 'eval_runtime': 39.4008, 'eval_samples_per_second': 17.918, 'eval_steps_per_second': 4.492, 'epoch': 9.74, 'step': 13000}

24-Jan-24 14:39:37 - {'loss': 0.2494, 'learning_rate': 5.132398753894081e-05, 'epoch': 10.12, 'step': 13500}

24-Jan-24 14:39:37 - {'loss': 0.2437, 'learning_rate': 4.937694704049845e-05, 'epoch': 10.49, 'step': 14000}

24-Jan-24 14:39:37 - {'eval_loss': 1.8257776498794556, 'eval_wer': 0.3788659793814433, 'eval_runtime': 39.4467, 'eval_samples_per_second': 17.898, 'eval_steps_per_second': 4.487, 'epoch': 10.49, 'step': 14000}

24-Jan-24 14:39:37 - {'loss': 0.2427, 'learning_rate': 4.742990654205608e-05, 'epoch': 10.87, 'step': 14500}

24-Jan-24 14:39:37 - {'loss': 0.2226, 'learning_rate': 4.548286604361371e-05, 'epoch': 11.24, 'step': 15000}

24-Jan-24 14:39:37 - {'eval_loss': 1.5750610828399658, 'eval_wer': 0.33505154639175255, 'eval_runtime': 39.2624, 'eval_samples_per_second': 17.982, 'eval_steps_per_second': 4.508, 'epoch': 11.24, 'step': 15000}

24-Jan-24 14:39:37 - {'loss': 0.225, 'learning_rate': 4.353582554517134e-05, 'epoch': 11.62, 'step': 15500}

24-Jan-24 14:39:37 - {'loss': 0.2059, 'learning_rate': 4.1588785046728974e-05, 'epoch': 11.99, 'step': 16000}

24-Jan-24 14:39:37 - {'eval_loss': 1.5210517644882202, 'eval_wer': 0.32603092783505155, 'eval_runtime': 39.5537, 'eval_samples_per_second': 17.849, 'eval_steps_per_second': 4.475, 'epoch': 11.99, 'step': 16000}

24-Jan-24 14:39:37 - {'loss': 0.1923, 'learning_rate': 3.9641744548286606e-05, 'epoch': 12.37, 'step': 16500}

24-Jan-24 14:39:37 - {'loss': 0.2244, 'learning_rate': 3.769470404984424e-05, 'epoch': 12.74, 'step': 17000}

24-Jan-24 14:39:37 - {'eval_loss': 1.3020797967910767, 'eval_wer': 0.31958762886597936, 'eval_runtime': 39.9874, 'eval_samples_per_second': 17.656, 'eval_steps_per_second': 4.426, 'epoch': 12.74, 'step': 17000}

24-Jan-24 14:39:37 - {'loss': 0.195, 'learning_rate': 3.574766355140187e-05, 'epoch': 13.12, 'step': 17500}

24-Jan-24 14:39:37 - {'loss': 0.1904, 'learning_rate': 3.38006230529595e-05, 'epoch': 13.49, 'step': 18000}

24-Jan-24 14:39:37 - {'eval_loss': 1.8145990371704102, 'eval_wer': 0.3556701030927835, 'eval_runtime': 39.8007, 'eval_samples_per_second': 17.738, 'eval_steps_per_second': 4.447, 'epoch': 13.49, 'step': 18000}

24-Jan-24 14:39:37 - {'loss': 0.1861, 'learning_rate': 3.185358255451714e-05, 'epoch': 13.87, 'step': 18500}

24-Jan-24 14:39:37 - {'loss': 0.2026, 'learning_rate': 2.9906542056074764e-05, 'epoch': 14.24, 'step': 19000}

24-Jan-24 14:39:37 - {'eval_loss': 1.6795192956924438, 'eval_wer': 0.33054123711340205, 'eval_runtime': 39.9329, 'eval_samples_per_second': 17.68, 'eval_steps_per_second': 4.432, 'epoch': 14.24, 'step': 19000}

24-Jan-24 14:39:37 - {'loss': 0.175, 'learning_rate': 2.79595015576324e-05, 'epoch': 14.62, 'step': 19500}

24-Jan-24 14:39:37 - {'loss': 0.1696, 'learning_rate': 2.601246105919003e-05, 'epoch': 14.99, 'step': 20000}

24-Jan-24 14:39:37 - {'eval_loss': 1.4433722496032715, 'eval_wer': 0.29896907216494845, 'eval_runtime': 40.0347, 'eval_samples_per_second': 17.635, 'eval_steps_per_second': 4.421, 'epoch': 14.99, 'step': 20000}

24-Jan-24 14:39:37 - {'loss': 0.1593, 'learning_rate': 2.4065420560747666e-05, 'epoch': 15.37, 'step': 20500}

24-Jan-24 14:39:37 - {'loss': 0.1753, 'learning_rate': 2.2118380062305298e-05, 'epoch': 15.74, 'step': 21000}

24-Jan-24 14:39:37 - {'eval_loss': 1.5750869512557983, 'eval_wer': 0.2957474226804124, 'eval_runtime': 40.1781, 'eval_samples_per_second': 17.572, 'eval_steps_per_second': 4.405, 'epoch': 15.74, 'step': 21000}

24-Jan-24 14:39:37 - {'loss': 0.1855, 'learning_rate': 2.017133956386293e-05, 'epoch': 16.12, 'step': 21500}

24-Jan-24 14:39:37 - {'loss': 0.1648, 'learning_rate': 1.822429906542056e-05, 'epoch': 16.49, 'step': 22000}

24-Jan-24 14:39:37 - {'eval_loss': 1.743213176727295, 'eval_wer': 0.30476804123711343, 'eval_runtime': 39.7025, 'eval_samples_per_second': 17.782, 'eval_steps_per_second': 4.458, 'epoch': 16.49, 'step': 22000}

24-Jan-24 14:39:37 - {'loss': 0.1465, 'learning_rate': 1.6277258566978192e-05, 'epoch': 16.87, 'step': 22500}

24-Jan-24 14:39:37 - {'loss': 0.1364, 'learning_rate': 1.4330218068535826e-05, 'epoch': 17.24, 'step': 23000}

24-Jan-24 14:39:37 - {'eval_loss': 1.850088357925415, 'eval_wer': 0.32667525773195877, 'eval_runtime': 39.8137, 'eval_samples_per_second': 17.733, 'eval_steps_per_second': 4.446, 'epoch': 17.24, 'step': 23000}

24-Jan-24 14:39:37 - {'loss': 0.1432, 'learning_rate': 1.2383177570093459e-05, 'epoch': 17.62, 'step': 23500}

24-Jan-24 14:39:37 - {'loss': 0.1499, 'learning_rate': 1.043613707165109e-05, 'epoch': 17.99, 'step': 24000}

24-Jan-24 14:39:37 - {'eval_loss': 1.6999127864837646, 'eval_wer': 0.30476804123711343, 'eval_runtime': 39.8301, 'eval_samples_per_second': 17.725, 'eval_steps_per_second': 4.444, 'epoch': 17.99, 'step': 24000}

24-Jan-24 14:39:37 - {'loss': 0.119, 'learning_rate': 8.489096573208722e-06, 'epoch': 18.37, 'step': 24500}

24-Jan-24 14:39:37 - {'loss': 0.1452, 'learning_rate': 6.542056074766355e-06, 'epoch': 18.74, 'step': 25000}

24-Jan-24 14:39:37 - {'eval_loss': 1.7274088859558105, 'eval_wer': 0.2970360824742268, 'eval_runtime': 39.8331, 'eval_samples_per_second': 17.724, 'eval_steps_per_second': 4.444, 'epoch': 18.74, 'step': 25000}

24-Jan-24 14:39:37 - {'loss': 0.1476, 'learning_rate': 4.595015576323987e-06, 'epoch': 19.12, 'step': 25500}

24-Jan-24 14:39:37 - {'loss': 0.1367, 'learning_rate': 2.64797507788162e-06, 'epoch': 19.49, 'step': 26000}

24-Jan-24 14:39:37 - {'eval_loss': 1.69442617893219, 'eval_wer': 0.29510309278350516, 'eval_runtime': 39.7527, 'eval_samples_per_second': 17.76, 'eval_steps_per_second': 4.453, 'epoch': 19.49, 'step': 26000}

24-Jan-24 14:39:37 - {'loss': 0.1367, 'learning_rate': 7.009345794392523e-07, 'epoch': 19.86, 'step': 26500}

24-Jan-24 14:39:37 - {'train_runtime': 25764.4726, 'train_samples_per_second': 8.287, 'train_steps_per_second': 1.036, 'total_flos': 1.7492594485984453e+19, 'train_loss': 0.9391050287987339, 'epoch': 20.0, 'step': 26680}

24-Jan-24 14:41:16 - To https://huggingface.co/macarious/torgo_xlsr_finetune_M04
   bfd0958..5d591f3  main -> main

24-Jan-24 14:41:31 - To https://huggingface.co/macarious/torgo_xlsr_finetune_M04
   5d591f3..a79b239  main -> main

24-Jan-24 14:41:34 - Model pushed to Hugging Face Hub.

24-Jan-24 14:41:34 - Start Evaluation
