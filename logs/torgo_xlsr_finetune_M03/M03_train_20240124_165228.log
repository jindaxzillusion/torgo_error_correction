24-Jan-24 16:52:28 - Test Speaker: M03
24-Jan-24 16:52:28 - Number of epochs: 20
24-Jan-24 16:52:28 - Log File Path: /output/logs/M03_20240124_165228.log

24-Jan-24 16:52:28 - Using GPU: Tesla T4

24-Jan-24 16:52:28 - Unique speakers found in the dataset:
24-Jan-24 16:52:28 - ['F01' 'F03' 'F04' 'FC01' 'FC02' 'FC03' 'M01' 'M02' 'M03' 'M04' 'M05'
 'MC01' 'MC02' 'MC03' 'MC04']

24-Jan-24 16:52:29 - After applying the text count threshold of 40, the number of data in each dataset is:
24-Jan-24 16:52:29 - Train:       8534/14519 (58%)
24-Jan-24 16:52:29 - Validation:  542/1075 (50%)
24-Jan-24 16:52:29 - Test:        573/800 (71%)

24-Jan-24 16:52:30 - Vocab Dictionary:
24-Jan-24 16:52:30 - {'[PAD]': 0, '<s>': 1, '</s>': 2, '[UNK]': 3, "'": 4, 'a': 5, 'b': 6, 'c': 7, 'd': 8, 'e': 9, 'f': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'n': 18, 'o': 19, 'p': 20, 'q': 21, 'r': 22, 's': 23, 't': 24, 'u': 25, 'v': 26, 'w': 27, 'x': 28, 'y': 29, 'z': 30, '|': 31}

24-Jan-24 16:53:06 - After filtering audio within a certain length, the number of data in each dataset is:
24-Jan-24 16:53:06 - Train:       8479/14519 (58%)
24-Jan-24 16:53:06 - Validation:  520/1075 (48%)
24-Jan-24 16:53:06 - Test:        573/800 (71%)

24-Jan-24 16:53:22 - /output/model/torgo_xlsr_finetune_M03 is already a clone of https://huggingface.co/macarious/torgo_xlsr_finetune_M03. Make sure you pull the latest changes with `repo.git_pull()`.
24-Jan-24 16:53:24 - Start Training
24-Jan-24 16:53:24 - Training Arguments:
24-Jan-24 16:53:24 - {'Training Epochs': 20, 'Training Batch Size': 4, 'Evaluation Batch Size': 4, 'Learning Rate': 0.0001, 'Weight Decay': 0.005}
24-Jan-24 16:53:24 - Checkpoint found in the repository. Checkpoint files found: ['checkpoint-20000', 'checkpoint-20500', 'checkpoint-21000']
24-Jan-24 16:53:24 - Resuming from checkpoint: /output/model/torgo_xlsr_finetune_M03/checkpoint-21000

24-Jan-24 16:59:35 - Training completed in 0:06:11.620444

24-Jan-24 16:59:35 - Training Log Metrics:
24-Jan-24 16:59:35 - {'epoch': 0.47, 'learning_rate': 5e-05, 'loss': 25.4561, 'step': 500}

24-Jan-24 16:59:35 - {'epoch': 0.94, 'learning_rate': 0.0001, 'loss': 3.5549, 'step': 1000}

24-Jan-24 16:59:35 - {'epoch': 0.94, 'eval_loss': 3.3499672412872314, 'eval_runtime': 27.0635, 'eval_samples_per_second': 19.214, 'eval_steps_per_second': 4.804, 'eval_wer': 1.0, 'step': 1000}

24-Jan-24 16:59:35 - {'epoch': 1.42, 'learning_rate': 9.752475247524753e-05, 'loss': 3.078, 'step': 1500}

24-Jan-24 16:59:35 - {'epoch': 1.89, 'learning_rate': 9.504950495049505e-05, 'loss': 1.6884, 'step': 2000}

24-Jan-24 16:59:35 - {'epoch': 1.89, 'eval_loss': 1.729059100151062, 'eval_runtime': 27.2573, 'eval_samples_per_second': 19.077, 'eval_steps_per_second': 4.769, 'eval_wer': 0.8172541743970315, 'step': 2000}

24-Jan-24 16:59:35 - {'epoch': 2.36, 'learning_rate': 9.257425742574259e-05, 'loss': 1.0785, 'step': 2500}

24-Jan-24 16:59:35 - {'epoch': 2.83, 'learning_rate': 9.009900990099011e-05, 'loss': 0.8237, 'step': 3000}

24-Jan-24 16:59:35 - {'epoch': 2.83, 'eval_loss': 1.4607645273208618, 'eval_runtime': 27.1979, 'eval_samples_per_second': 19.119, 'eval_steps_per_second': 4.78, 'eval_wer': 0.6567717996289425, 'step': 3000}

24-Jan-24 16:59:35 - {'epoch': 3.3, 'learning_rate': 8.762376237623763e-05, 'loss': 0.6778, 'step': 3500}

24-Jan-24 16:59:35 - {'epoch': 3.77, 'learning_rate': 8.514851485148515e-05, 'loss': 0.6483, 'step': 4000}

24-Jan-24 16:59:35 - {'epoch': 3.77, 'eval_loss': 1.1613399982452393, 'eval_runtime': 27.2637, 'eval_samples_per_second': 19.073, 'eval_steps_per_second': 4.768, 'eval_wer': 0.49536178107606677, 'step': 4000}

24-Jan-24 16:59:35 - {'epoch': 4.25, 'learning_rate': 8.267326732673268e-05, 'loss': 0.5679, 'step': 4500}

24-Jan-24 16:59:35 - {'epoch': 4.72, 'learning_rate': 8.019801980198021e-05, 'loss': 0.5299, 'step': 5000}

24-Jan-24 16:59:35 - {'epoch': 4.72, 'eval_loss': 1.5724717378616333, 'eval_runtime': 27.2105, 'eval_samples_per_second': 19.11, 'eval_steps_per_second': 4.778, 'eval_wer': 0.48237476808905383, 'step': 5000}

24-Jan-24 16:59:35 - {'epoch': 5.19, 'learning_rate': 7.772277227722773e-05, 'loss': 0.4552, 'step': 5500}

24-Jan-24 16:59:35 - {'epoch': 5.66, 'learning_rate': 7.524752475247526e-05, 'loss': 0.4091, 'step': 6000}

24-Jan-24 16:59:35 - {'epoch': 5.66, 'eval_loss': 1.4436887502670288, 'eval_runtime': 27.3106, 'eval_samples_per_second': 19.04, 'eval_steps_per_second': 4.76, 'eval_wer': 0.4684601113172542, 'step': 6000}

24-Jan-24 16:59:35 - {'epoch': 6.13, 'learning_rate': 7.277227722772278e-05, 'loss': 0.4005, 'step': 6500}

24-Jan-24 16:59:35 - {'epoch': 6.6, 'learning_rate': 7.02970297029703e-05, 'loss': 0.3694, 'step': 7000}

24-Jan-24 16:59:35 - {'epoch': 6.6, 'eval_loss': 1.4507126808166504, 'eval_runtime': 27.0398, 'eval_samples_per_second': 19.231, 'eval_steps_per_second': 4.808, 'eval_wer': 0.4397031539888683, 'step': 7000}

24-Jan-24 16:59:35 - {'epoch': 7.08, 'learning_rate': 6.782178217821783e-05, 'loss': 0.3731, 'step': 7500}

24-Jan-24 16:59:35 - {'epoch': 7.55, 'learning_rate': 6.534653465346535e-05, 'loss': 0.3515, 'step': 8000}

24-Jan-24 16:59:35 - {'epoch': 7.55, 'eval_loss': 1.439749836921692, 'eval_runtime': 27.1153, 'eval_samples_per_second': 19.177, 'eval_steps_per_second': 4.794, 'eval_wer': 0.4230055658627087, 'step': 8000}

24-Jan-24 16:59:35 - {'epoch': 8.02, 'learning_rate': 6.287128712871287e-05, 'loss': 0.341, 'step': 8500}

24-Jan-24 16:59:35 - {'epoch': 8.49, 'learning_rate': 6.03960396039604e-05, 'loss': 0.2878, 'step': 9000}

24-Jan-24 16:59:35 - {'epoch': 8.49, 'eval_loss': 1.4089431762695312, 'eval_runtime': 27.1232, 'eval_samples_per_second': 19.172, 'eval_steps_per_second': 4.793, 'eval_wer': 0.3979591836734694, 'step': 9000}

24-Jan-24 16:59:35 - {'epoch': 8.96, 'learning_rate': 5.792079207920792e-05, 'loss': 0.3178, 'step': 9500}

24-Jan-24 16:59:35 - {'epoch': 9.43, 'learning_rate': 5.544554455445545e-05, 'loss': 0.2698, 'step': 10000}

24-Jan-24 16:59:35 - {'epoch': 9.43, 'eval_loss': 1.4695502519607544, 'eval_runtime': 27.4402, 'eval_samples_per_second': 18.95, 'eval_steps_per_second': 4.738, 'eval_wer': 0.37755102040816324, 'step': 10000}

24-Jan-24 16:59:35 - {'epoch': 9.91, 'learning_rate': 5.2970297029702974e-05, 'loss': 0.2834, 'step': 10500}

24-Jan-24 16:59:35 - {'epoch': 10.38, 'learning_rate': 5.0495049504950497e-05, 'loss': 0.2621, 'step': 11000}

24-Jan-24 16:59:35 - {'epoch': 10.38, 'eval_loss': 1.671686053276062, 'eval_runtime': 27.1373, 'eval_samples_per_second': 19.162, 'eval_steps_per_second': 4.79, 'eval_wer': 0.39053803339517623, 'step': 11000}

24-Jan-24 16:59:35 - {'epoch': 10.85, 'learning_rate': 4.801980198019802e-05, 'loss': 0.2572, 'step': 11500}

24-Jan-24 16:59:35 - {'epoch': 11.32, 'learning_rate': 4.554455445544555e-05, 'loss': 0.2465, 'step': 12000}

24-Jan-24 16:59:35 - {'epoch': 11.32, 'eval_loss': 1.6235013008117676, 'eval_runtime': 27.0765, 'eval_samples_per_second': 19.205, 'eval_steps_per_second': 4.801, 'eval_wer': 0.35435992578849723, 'step': 12000}

24-Jan-24 16:59:35 - {'epoch': 11.79, 'learning_rate': 4.306930693069307e-05, 'loss': 0.2364, 'step': 12500}

24-Jan-24 16:59:35 - {'epoch': 12.26, 'learning_rate': 4.05940594059406e-05, 'loss': 0.221, 'step': 13000}

24-Jan-24 16:59:35 - {'epoch': 12.26, 'eval_loss': 1.4008615016937256, 'eval_runtime': 27.206, 'eval_samples_per_second': 19.113, 'eval_steps_per_second': 4.778, 'eval_wer': 0.34786641929499074, 'step': 13000}

24-Jan-24 16:59:35 - {'epoch': 12.74, 'learning_rate': 3.811881188118812e-05, 'loss': 0.2185, 'step': 13500}

24-Jan-24 16:59:35 - {'epoch': 13.21, 'learning_rate': 3.5643564356435645e-05, 'loss': 0.2169, 'step': 14000}

24-Jan-24 16:59:35 - {'epoch': 13.21, 'eval_loss': 1.6980578899383545, 'eval_runtime': 27.0539, 'eval_samples_per_second': 19.221, 'eval_steps_per_second': 4.805, 'eval_wer': 0.36363636363636365, 'step': 14000}

24-Jan-24 16:59:35 - {'epoch': 13.68, 'learning_rate': 3.3168316831683175e-05, 'loss': 0.202, 'step': 14500}

24-Jan-24 16:59:35 - {'epoch': 14.15, 'learning_rate': 3.06930693069307e-05, 'loss': 0.187, 'step': 15000}

24-Jan-24 16:59:35 - {'epoch': 14.15, 'eval_loss': 1.4411181211471558, 'eval_runtime': 27.2165, 'eval_samples_per_second': 19.106, 'eval_steps_per_second': 4.777, 'eval_wer': 0.3302411873840445, 'step': 15000}

24-Jan-24 16:59:35 - {'epoch': 14.62, 'learning_rate': 2.8217821782178216e-05, 'loss': 0.1874, 'step': 15500}

24-Jan-24 16:59:35 - {'epoch': 15.09, 'learning_rate': 2.5742574257425746e-05, 'loss': 0.1918, 'step': 16000}

24-Jan-24 16:59:35 - {'epoch': 15.09, 'eval_loss': 1.6417640447616577, 'eval_runtime': 27.2851, 'eval_samples_per_second': 19.058, 'eval_steps_per_second': 4.765, 'eval_wer': 0.33766233766233766, 'step': 16000}

24-Jan-24 16:59:35 - {'epoch': 15.57, 'learning_rate': 2.326732673267327e-05, 'loss': 0.1825, 'step': 16500}

24-Jan-24 16:59:35 - {'epoch': 16.04, 'learning_rate': 2.079207920792079e-05, 'loss': 0.1876, 'step': 17000}

24-Jan-24 16:59:35 - {'epoch': 16.04, 'eval_loss': 1.4613168239593506, 'eval_runtime': 27.2049, 'eval_samples_per_second': 19.114, 'eval_steps_per_second': 4.779, 'eval_wer': 0.3339517625231911, 'step': 17000}

24-Jan-24 16:59:35 - {'epoch': 16.51, 'learning_rate': 1.8316831683168317e-05, 'loss': 0.1832, 'step': 17500}

24-Jan-24 16:59:35 - {'epoch': 16.98, 'learning_rate': 1.5841584158415843e-05, 'loss': 0.1641, 'step': 18000}

24-Jan-24 16:59:35 - {'epoch': 16.98, 'eval_loss': 1.6039983034133911, 'eval_runtime': 27.3483, 'eval_samples_per_second': 19.014, 'eval_steps_per_second': 4.753, 'eval_wer': 0.33116883116883117, 'step': 18000}

24-Jan-24 16:59:35 - {'epoch': 17.45, 'learning_rate': 1.3366336633663367e-05, 'loss': 0.1602, 'step': 18500}

24-Jan-24 16:59:35 - {'epoch': 17.92, 'learning_rate': 1.0891089108910891e-05, 'loss': 0.1546, 'step': 19000}

24-Jan-24 16:59:35 - {'epoch': 17.92, 'eval_loss': 1.6096007823944092, 'eval_runtime': 27.31, 'eval_samples_per_second': 19.041, 'eval_steps_per_second': 4.76, 'eval_wer': 0.3293135435992579, 'step': 19000}

24-Jan-24 16:59:35 - {'epoch': 18.4, 'learning_rate': 8.415841584158417e-06, 'loss': 0.1516, 'step': 19500}

24-Jan-24 16:59:35 - {'epoch': 18.87, 'learning_rate': 5.940594059405941e-06, 'loss': 0.1522, 'step': 20000}

24-Jan-24 16:59:35 - {'epoch': 18.87, 'eval_loss': 1.7269947528839111, 'eval_runtime': 27.509, 'eval_samples_per_second': 18.903, 'eval_steps_per_second': 4.726, 'eval_wer': 0.32653061224489793, 'step': 20000}

24-Jan-24 16:59:35 - {'epoch': 19.34, 'learning_rate': 3.4653465346534657e-06, 'loss': 0.1587, 'step': 20500}

24-Jan-24 16:59:35 - {'epoch': 19.81, 'learning_rate': 9.900990099009902e-07, 'loss': 0.1332, 'step': 21000}

24-Jan-24 16:59:35 - {'epoch': 19.81, 'eval_loss': 1.6992913484573364, 'eval_runtime': 27.4069, 'eval_samples_per_second': 18.973, 'eval_steps_per_second': 4.743, 'eval_wer': 0.3246753246753247, 'step': 21000}

24-Jan-24 16:59:35 - {'train_runtime': 262.4496, 'train_samples_per_second': 646.143, 'train_steps_per_second': 80.777, 'total_flos': 1.3400901222398552e+19, 'train_loss': 0.0010242938095668577, 'epoch': 20.0, 'step': 21200}

24-Jan-24 17:01:08 - To https://huggingface.co/macarious/torgo_xlsr_finetune_M03
   4bb0a49..80dd78e  main -> main

24-Jan-24 17:01:21 - To https://huggingface.co/macarious/torgo_xlsr_finetune_M03
   80dd78e..d8cc76c  main -> main

24-Jan-24 17:01:24 - Model pushed to Hugging Face Hub.

24-Jan-24 17:01:24 - Start Evaluation
24-Jan-24 17:01:58 - Predicting on the training set...
24-Jan-24 17:10:40 - Word Error Rate: 0.01240268456375839
24-Jan-24 17:10:41 - Predictions saved to: /output/results/torgo_xlsr_finetune_M03/M03_predictions_train.csv

24-Jan-24 17:10:41 - Predicting on the validation set...
24-Jan-24 17:11:12 - Word Error Rate: 0.3246753246753247
24-Jan-24 17:11:12 - Predictions saved to: /output/results/torgo_xlsr_finetune_M03/M03_predictions_validation.csv

24-Jan-24 17:11:12 - Predicting on the test set...
24-Jan-24 17:11:55 - Word Error Rate: 0.4194088120468489
24-Jan-24 17:11:55 - Predictions saved to: /output/results/torgo_xlsr_finetune_M03/M03_predictions_test.csv

24-Jan-24 17:11:55 - Summary of Word Error Rates saved to /output/results/torgo_xlsr_finetune_M03/M03_wer_summary.csv

24-Jan-24 17:11:55 - End of Script
