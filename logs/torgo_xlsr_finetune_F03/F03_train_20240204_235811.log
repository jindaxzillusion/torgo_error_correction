04-Feb-24 23:58:11 - Test Speaker: F03
04-Feb-24 23:58:11 - Log File Path: /output/logs/torgo_xlsr_finetune_F03/F03_train_20240204_235811.log

04-Feb-24 23:58:11 - Using GPU: Tesla T4

04-Feb-24 23:58:11 - Splitting the dataset into training / validation / test sets...
04-Feb-24 23:58:11 - Unique speakers found in the dataset:
04-Feb-24 23:58:11 - ['F01' 'F03' 'F04' 'FC01' 'FC02' 'FC03' 'M01' 'M02' 'M03' 'M04' 'M05'
 'MC01' 'MC02' 'MC03' 'MC04']

04-Feb-24 23:58:12 - After applying the text count threshold of 40, the number of data in each dataset is:
04-Feb-24 23:58:12 - Train:       7601/14652 (51%)
04-Feb-24 23:58:12 - Validation:  252/667 (37%)
04-Feb-24 23:58:12 - Test:        794/1075 (73%)

04-Feb-24 23:58:13 - Vocab Dictionary:
04-Feb-24 23:58:13 - {'[PAD]': 0, '<s>': 1, '</s>': 2, '[UNK]': 3, "'": 4, 'a': 5, 'b': 6, 'c': 7, 'd': 8, 'e': 9, 'f': 10, 'g': 11, 'h': 12, 'i': 13, 'j': 14, 'k': 15, 'l': 16, 'm': 17, 'n': 18, 'o': 19, 'p': 20, 'q': 21, 'r': 22, 's': 23, 't': 24, 'u': 25, 'v': 26, 'w': 27, 'x': 28, 'y': 29, 'z': 30, '|': 31}

04-Feb-24 23:58:49 - After filtering audio within a certain length, the number of data in each dataset is:
04-Feb-24 23:58:49 - Train:       7567/14652 (51%)
04-Feb-24 23:58:49 - Validation:  245/667 (36%)
04-Feb-24 23:58:49 - Test:        756/1075 (70%)

04-Feb-24 23:58:55 - Cloning https://huggingface.co/macarious/torgo_xlsr_finetune_F03 into local empty directory.
04-Feb-24 23:59:00 - Start Training
04-Feb-24 23:59:00 - Training Arguments:
04-Feb-24 23:59:00 - {'Training Epochs': 20, 'Training Batch Size': 4, 'Evaluation Batch Size': 4, 'Learning Rate': 0.0001, 'Weight Decay': 0.005}
04-Feb-24 23:59:00 - No checkpoint found in the repository. Training from scratch.
05-Feb-24 00:13:40 - Current Word Error Rate: 1.0
05-Feb-24 00:28:41 - Current Word Error Rate: 0.7401574803149606
05-Feb-24 00:43:37 - Current Word Error Rate: 0.42782152230971127
05-Feb-24 00:58:36 - Current Word Error Rate: 0.27034120734908135
05-Feb-24 01:13:36 - Current Word Error Rate: 0.18635170603674542
05-Feb-24 01:28:33 - Current Word Error Rate: 0.15485564304461943
05-Feb-24 01:43:31 - Current Word Error Rate: 0.1732283464566929
05-Feb-24 01:58:28 - Current Word Error Rate: 0.13385826771653545
05-Feb-24 02:13:27 - Current Word Error Rate: 0.12335958005249344
05-Feb-24 02:28:32 - Current Word Error Rate: 0.1784776902887139
05-Feb-24 02:43:36 - Current Word Error Rate: 0.14173228346456693
05-Feb-24 02:58:33 - Current Word Error Rate: 0.13385826771653545
05-Feb-24 03:13:38 - Current Word Error Rate: 0.11548556430446194
05-Feb-24 03:28:32 - Current Word Error Rate: 0.12860892388451445
05-Feb-24 03:43:32 - Current Word Error Rate: 0.13385826771653545
05-Feb-24 03:58:33 - Current Word Error Rate: 0.12860892388451445
05-Feb-24 04:13:31 - Current Word Error Rate: 0.12598425196850394
05-Feb-24 04:28:32 - Current Word Error Rate: 0.12335958005249344
05-Feb-24 04:42:10 - Training completed in 4:43:10.301642

05-Feb-24 04:42:10 - Training Log Metrics:
05-Feb-24 04:42:10 - {'loss': 29.0492, 'learning_rate': 5e-05, 'epoch': 0.53, 'step': 500}

05-Feb-24 04:42:10 - {'loss': 3.5793, 'learning_rate': 0.0001, 'epoch': 1.06, 'step': 1000}

05-Feb-24 04:42:10 - {'eval_loss': 3.5545105934143066, 'eval_wer': 1.0, 'eval_runtime': 15.4517, 'eval_samples_per_second': 15.856, 'eval_steps_per_second': 4.013, 'epoch': 1.06, 'step': 1000}

05-Feb-24 04:42:10 - {'loss': 3.3227, 'learning_rate': 9.720982142857144e-05, 'epoch': 1.59, 'step': 1500}

05-Feb-24 04:42:10 - {'loss': 2.1557, 'learning_rate': 9.441964285714286e-05, 'epoch': 2.11, 'step': 2000}

05-Feb-24 04:42:10 - {'eval_loss': 0.9675420522689819, 'eval_wer': 0.7401574803149606, 'eval_runtime': 15.409, 'eval_samples_per_second': 15.9, 'eval_steps_per_second': 4.024, 'epoch': 2.11, 'step': 2000}

05-Feb-24 04:42:10 - {'loss': 1.1805, 'learning_rate': 9.16294642857143e-05, 'epoch': 2.64, 'step': 2500}

05-Feb-24 04:42:10 - {'loss': 0.9155, 'learning_rate': 8.883928571428571e-05, 'epoch': 3.17, 'step': 3000}

05-Feb-24 04:42:10 - {'eval_loss': 0.5581374764442444, 'eval_wer': 0.42782152230971127, 'eval_runtime': 15.4332, 'eval_samples_per_second': 15.875, 'eval_steps_per_second': 4.017, 'epoch': 3.17, 'step': 3000}

05-Feb-24 04:42:10 - {'loss': 0.7597, 'learning_rate': 8.604910714285714e-05, 'epoch': 3.7, 'step': 3500}

05-Feb-24 04:42:10 - {'loss': 0.6488, 'learning_rate': 8.325892857142858e-05, 'epoch': 4.23, 'step': 4000}

05-Feb-24 04:42:10 - {'eval_loss': 0.47530242800712585, 'eval_wer': 0.27034120734908135, 'eval_runtime': 15.4766, 'eval_samples_per_second': 15.83, 'eval_steps_per_second': 4.006, 'epoch': 4.23, 'step': 4000}

05-Feb-24 04:42:10 - {'loss': 0.5573, 'learning_rate': 8.046875e-05, 'epoch': 4.76, 'step': 4500}

05-Feb-24 04:42:10 - {'loss': 0.4806, 'learning_rate': 7.767857142857144e-05, 'epoch': 5.29, 'step': 5000}

05-Feb-24 04:42:10 - {'eval_loss': 0.5098758339881897, 'eval_wer': 0.18635170603674542, 'eval_runtime': 15.4937, 'eval_samples_per_second': 15.813, 'eval_steps_per_second': 4.002, 'epoch': 5.29, 'step': 5000}

05-Feb-24 04:42:10 - {'loss': 0.4995, 'learning_rate': 7.488839285714286e-05, 'epoch': 5.81, 'step': 5500}

05-Feb-24 04:42:10 - {'loss': 0.4012, 'learning_rate': 7.20982142857143e-05, 'epoch': 6.34, 'step': 6000}

05-Feb-24 04:42:10 - {'eval_loss': 0.3734274208545685, 'eval_wer': 0.15485564304461943, 'eval_runtime': 15.4876, 'eval_samples_per_second': 15.819, 'eval_steps_per_second': 4.003, 'epoch': 6.34, 'step': 6000}

05-Feb-24 04:42:10 - {'loss': 0.4277, 'learning_rate': 6.930803571428572e-05, 'epoch': 6.87, 'step': 6500}

05-Feb-24 04:42:10 - {'loss': 0.3717, 'learning_rate': 6.651785714285714e-05, 'epoch': 7.4, 'step': 7000}

05-Feb-24 04:42:10 - {'eval_loss': 0.49553564190864563, 'eval_wer': 0.1732283464566929, 'eval_runtime': 15.4412, 'eval_samples_per_second': 15.867, 'eval_steps_per_second': 4.015, 'epoch': 7.4, 'step': 7000}

05-Feb-24 04:42:10 - {'loss': 0.3596, 'learning_rate': 6.372767857142857e-05, 'epoch': 7.93, 'step': 7500}

05-Feb-24 04:42:10 - {'loss': 0.3247, 'learning_rate': 6.0937500000000004e-05, 'epoch': 8.46, 'step': 8000}

05-Feb-24 04:42:10 - {'eval_loss': 0.41866785287857056, 'eval_wer': 0.13385826771653545, 'eval_runtime': 15.4392, 'eval_samples_per_second': 15.869, 'eval_steps_per_second': 4.016, 'epoch': 8.46, 'step': 8000}

05-Feb-24 04:42:10 - {'loss': 0.3063, 'learning_rate': 5.814732142857143e-05, 'epoch': 8.99, 'step': 8500}

05-Feb-24 04:42:10 - {'loss': 0.3028, 'learning_rate': 5.535714285714286e-05, 'epoch': 9.51, 'step': 9000}

05-Feb-24 04:42:10 - {'eval_loss': 0.39202237129211426, 'eval_wer': 0.12335958005249344, 'eval_runtime': 15.5649, 'eval_samples_per_second': 15.741, 'eval_steps_per_second': 3.983, 'epoch': 9.51, 'step': 9000}

05-Feb-24 04:42:10 - {'loss': 0.2799, 'learning_rate': 5.256696428571429e-05, 'epoch': 10.04, 'step': 9500}

05-Feb-24 04:42:10 - {'loss': 0.2716, 'learning_rate': 4.977678571428572e-05, 'epoch': 10.57, 'step': 10000}

05-Feb-24 04:42:10 - {'eval_loss': 0.6216250658035278, 'eval_wer': 0.1784776902887139, 'eval_runtime': 15.4857, 'eval_samples_per_second': 15.821, 'eval_steps_per_second': 4.004, 'epoch': 10.57, 'step': 10000}

05-Feb-24 04:42:10 - {'loss': 0.2555, 'learning_rate': 4.698660714285715e-05, 'epoch': 11.1, 'step': 10500}

05-Feb-24 04:42:10 - {'loss': 0.255, 'learning_rate': 4.419642857142857e-05, 'epoch': 11.63, 'step': 11000}

05-Feb-24 04:42:10 - {'eval_loss': 0.33102473616600037, 'eval_wer': 0.14173228346456693, 'eval_runtime': 15.5101, 'eval_samples_per_second': 15.796, 'eval_steps_per_second': 3.997, 'epoch': 11.63, 'step': 11000}

05-Feb-24 04:42:10 - {'loss': 0.2339, 'learning_rate': 4.140625e-05, 'epoch': 12.16, 'step': 11500}

05-Feb-24 04:42:10 - {'loss': 0.2418, 'learning_rate': 3.861607142857143e-05, 'epoch': 12.68, 'step': 12000}

05-Feb-24 04:42:10 - {'eval_loss': 0.36527219414711, 'eval_wer': 0.13385826771653545, 'eval_runtime': 15.4558, 'eval_samples_per_second': 15.852, 'eval_steps_per_second': 4.011, 'epoch': 12.68, 'step': 12000}

05-Feb-24 04:42:10 - {'loss': 0.2337, 'learning_rate': 3.582589285714286e-05, 'epoch': 13.21, 'step': 12500}

05-Feb-24 04:42:10 - {'loss': 0.2111, 'learning_rate': 3.303571428571429e-05, 'epoch': 13.74, 'step': 13000}

05-Feb-24 04:42:10 - {'eval_loss': 0.36773425340652466, 'eval_wer': 0.11548556430446194, 'eval_runtime': 15.4335, 'eval_samples_per_second': 15.875, 'eval_steps_per_second': 4.017, 'epoch': 13.74, 'step': 13000}

05-Feb-24 04:42:10 - {'loss': 0.1803, 'learning_rate': 3.0245535714285716e-05, 'epoch': 14.27, 'step': 13500}

05-Feb-24 04:42:10 - {'loss': 0.1996, 'learning_rate': 2.7455357142857145e-05, 'epoch': 14.8, 'step': 14000}

05-Feb-24 04:42:10 - {'eval_loss': 0.4038929045200348, 'eval_wer': 0.12860892388451445, 'eval_runtime': 15.4408, 'eval_samples_per_second': 15.867, 'eval_steps_per_second': 4.015, 'epoch': 14.8, 'step': 14000}

05-Feb-24 04:42:10 - {'loss': 0.2229, 'learning_rate': 2.4665178571428574e-05, 'epoch': 15.33, 'step': 14500}

05-Feb-24 04:42:10 - {'loss': 0.1869, 'learning_rate': 2.1875e-05, 'epoch': 15.86, 'step': 15000}

05-Feb-24 04:42:10 - {'eval_loss': 0.38112133741378784, 'eval_wer': 0.13385826771653545, 'eval_runtime': 15.5015, 'eval_samples_per_second': 15.805, 'eval_steps_per_second': 4.0, 'epoch': 15.86, 'step': 15000}

05-Feb-24 04:42:10 - {'loss': 0.1729, 'learning_rate': 1.908482142857143e-05, 'epoch': 16.38, 'step': 15500}

05-Feb-24 04:42:10 - {'loss': 0.175, 'learning_rate': 1.6294642857142858e-05, 'epoch': 16.91, 'step': 16000}

05-Feb-24 04:42:10 - {'eval_loss': 0.3736068904399872, 'eval_wer': 0.12860892388451445, 'eval_runtime': 15.4079, 'eval_samples_per_second': 15.901, 'eval_steps_per_second': 4.024, 'epoch': 16.91, 'step': 16000}

05-Feb-24 04:42:10 - {'loss': 0.1495, 'learning_rate': 1.3504464285714285e-05, 'epoch': 17.44, 'step': 16500}

05-Feb-24 04:42:10 - {'loss': 0.1651, 'learning_rate': 1.0714285714285714e-05, 'epoch': 17.97, 'step': 17000}

05-Feb-24 04:42:10 - {'eval_loss': 0.38482195138931274, 'eval_wer': 0.12598425196850394, 'eval_runtime': 15.5169, 'eval_samples_per_second': 15.789, 'eval_steps_per_second': 3.996, 'epoch': 17.97, 'step': 17000}

05-Feb-24 04:42:10 - {'loss': 0.1667, 'learning_rate': 7.924107142857143e-06, 'epoch': 18.5, 'step': 17500}

05-Feb-24 04:42:10 - {'loss': 0.179, 'learning_rate': 5.133928571428571e-06, 'epoch': 19.03, 'step': 18000}

05-Feb-24 04:42:10 - {'eval_loss': 0.37582921981811523, 'eval_wer': 0.12335958005249344, 'eval_runtime': 15.5206, 'eval_samples_per_second': 15.786, 'eval_steps_per_second': 3.995, 'epoch': 19.03, 'step': 18000}

05-Feb-24 04:42:10 - {'loss': 0.1485, 'learning_rate': 2.3437500000000002e-06, 'epoch': 19.56, 'step': 18500}

05-Feb-24 04:42:10 - {'train_runtime': 16903.1618, 'train_samples_per_second': 8.953, 'train_steps_per_second': 1.119, 'total_flos': 1.1880455734495773e+19, 'train_loss': 1.3131272644623642, 'epoch': 20.0, 'step': 18920}

05-Feb-24 04:42:10 - Pushing model to Hugging Face...
05-Feb-24 04:43:34 - To https://huggingface.co/macarious/torgo_xlsr_finetune_F03
   b6554a5..2d959c6  main -> main

05-Feb-24 04:43:38 - To https://huggingface.co/macarious/torgo_xlsr_finetune_F03
   2d959c6..4dc0f65  main -> main

05-Feb-24 04:43:41 - End of Script
05-Feb-24 04:43:41 - --------------------------------------------

