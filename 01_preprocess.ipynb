{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2b60b7-a838-497e-a0eb-4457d4601079",
   "metadata": {},
   "source": [
    "# COMMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b27a72d7-8146-4abc-a896-da06b36f520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27.0\n"
     ]
    }
   ],
   "source": [
    "%run 00_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d488a5b8-2cc8-4e0b-8d5a-ac5cbb3cbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the data\n",
    "# The preprocess_function function is defined to preprocess the data by tokenizing the inputs and labels\n",
    "def preprocess_function(examples):\n",
    "    inputs = [f'{source_lang}: {text}' for text in examples[source_lang]]\n",
    "    targets = examples[target_lang]\n",
    "    encoding = tokenizer(inputs, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
    "    model_inputs = {\n",
    "        'input_ids': encoding['input_ids'].squeeze(),\n",
    "        'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "        'labels': tokenizer(targets, padding=True, truncation=True, return_tensors='pt')['input_ids'].squeeze()\n",
    "    }\n",
    "    return model_inputs\n",
    "\n",
    "# define a data_collator function for batch processing\n",
    "def data_collator(features):\n",
    "    batch = {}\n",
    "    # Pad input_ids and attention_mask to the maximum length within the batch\n",
    "    max_length = max(len(feature['input_ids']) for feature in features)\n",
    "    batch['input_ids'] = torch.stack([torch.tensor(feature['input_ids'] + [tokenizer.pad_token_id] * (max_length - len(feature['input_ids']))) for feature in features])\n",
    "    batch['attention_mask'] = torch.stack([torch.tensor(feature['attention_mask'] + [0] * (max_length - len(feature['attention_mask']))) for feature in features])\n",
    "    batch['labels'] = torch.stack([torch.tensor(feature['labels'] + [-100] * (max_length - len(feature['labels']))) for feature in features])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad08702-415c-4aaf-a735-1c6969897972",
   "metadata": {},
   "source": [
    "# READ CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c15ffa6-5840-4739-b128-c5874d566e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "\n",
    "def load_dataframes(directory='results'):\n",
    "    dataframes = {}\n",
    "\n",
    "    for speaker_dir in os.listdir(directory):\n",
    "        if os.path.isdir(os.path.join(directory, speaker_dir)):\n",
    "            train_df = None\n",
    "            test_df = None\n",
    "            valid_df = None\n",
    "\n",
    "            for file in os.listdir(os.path.join(directory, speaker_dir)):\n",
    "                if file.endswith('.csv'):\n",
    "                    df_name = os.path.splitext(file)[0]\n",
    "                    df_path = os.path.join(directory, speaker_dir, file)\n",
    "\n",
    "                    if 'train' in df_name:\n",
    "                        if train_df is None:\n",
    "                            train_df = pd.read_csv(df_path)\n",
    "                        else:\n",
    "                            train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                    elif 'test' in df_name:\n",
    "                        if test_df is None:\n",
    "                            test_df = pd.read_csv(df_path)\n",
    "                        else:\n",
    "                            test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                    elif 'validation' in df_name:\n",
    "                        if valid_df is None:\n",
    "                            valid_df = pd.read_csv(df_path)\n",
    "                        else:\n",
    "                            valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "\n",
    "            combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "\n",
    "            if combined_df is not None:\n",
    "                dataframes[speaker_dir] = combined_df\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "dataframes = load_dataframes()\n",
    "\n",
    "\n",
    "# for df_name, df in dataframes.items():\n",
    "#     print(f'DataFrame: {df_name}')\n",
    "#     print(df)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73232ce-b96a-43f3-9e77-696d0b83f409",
   "metadata": {},
   "source": [
    "# SEPERATE CSV BY IF KEEP ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5602dd43-67ab-4f5b-8395-29c08296aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_keep_all = {}\n",
    "dataframes_no_keep_all = {}\n",
    "\n",
    "for speaker_dir in os.listdir('results'):\n",
    "    if os.path.isdir(os.path.join('results', speaker_dir)):\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "        valid_df = None\n",
    "\n",
    "        for file in os.listdir(os.path.join('results', speaker_dir)):\n",
    "            if file.endswith('.csv'):\n",
    "                df_name = os.path.splitext(file)[0]\n",
    "                df_path = os.path.join('results', speaker_dir, file)\n",
    "                \n",
    "                if 'train' in df_name:\n",
    "                    if train_df is None:\n",
    "                        train_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'test' in df_name:\n",
    "                    if test_df is None:\n",
    "                        test_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'validation' in df_name:\n",
    "                    if valid_df is None:\n",
    "                        valid_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "        \n",
    "        combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        if 'keep_all' in speaker_dir:\n",
    "            dataframes_keep_all[speaker_dir] = combined_df\n",
    "        else:\n",
    "            dataframes_no_keep_all[speaker_dir] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81dd0534-5855-4ca4-bb44-54acf80fd56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01 - Data Size: 14409\n",
      "torgo_xlsr_finetune_F03 - Data Size: 8568\n",
      "torgo_xlsr_finetune_F04 - Data Size: 9454\n",
      "torgo_xlsr_finetune_M01 - Data Size: 6540\n",
      "torgo_xlsr_finetune_M02 - Data Size: 9790\n",
      "torgo_xlsr_finetune_M03 - Data Size: 9572\n",
      "torgo_xlsr_finetune_M04 - Data Size: 11751\n",
      "torgo_xlsr_finetune_M05 - Data Size: 8853\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 16082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_dataframe_sizes(dataframes_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_keep_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc909ece-2f4e-408d-b0dd-d00a180a82f5",
   "metadata": {},
   "source": [
    "# SEPERATE SENTENCE AND WORD LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a47aca0-92a5-4122-85dd-61fdc084e2e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 12115\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 12129\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 3967\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 3953\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 10795\n",
      "torgo_xlsr_finetune_F03 - Data Size: 6813\n",
      "torgo_xlsr_finetune_F04 - Data Size: 7482\n",
      "torgo_xlsr_finetune_M01 - Data Size: 4404\n",
      "torgo_xlsr_finetune_M02 - Data Size: 7687\n",
      "torgo_xlsr_finetune_M03 - Data Size: 7480\n",
      "torgo_xlsr_finetune_M04 - Data Size: 9139\n",
      "torgo_xlsr_finetune_M05 - Data Size: 7178\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 3614\n",
      "torgo_xlsr_finetune_F03 - Data Size: 1755\n",
      "torgo_xlsr_finetune_F04 - Data Size: 1972\n",
      "torgo_xlsr_finetune_M01 - Data Size: 2136\n",
      "torgo_xlsr_finetune_M02 - Data Size: 2103\n",
      "torgo_xlsr_finetune_M03 - Data Size: 2092\n",
      "torgo_xlsr_finetune_M04 - Data Size: 2612\n",
      "torgo_xlsr_finetune_M05 - Data Size: 1675\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_29784/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all = {}\n",
    "dataframes_sentence_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "dataframes_word_no_keep_all = {}\n",
    "dataframes_sentence_no_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_no_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_no_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_no_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_no_keep_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bbe60-fc72-4f5f-82a6-ed97117873a2",
   "metadata": {},
   "source": [
    "# REMOVE SAME COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea7c23da-d20c-485a-abf0-718fe5ecf70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_dataframes(dataframes_dict, col_names):\n",
    "    processed_dataframes = {}\n",
    "\n",
    "    for df_name, df in dataframes_dict.items():\n",
    "        # Remove duplicates and drop NaN values\n",
    "        df = df.drop_duplicates(subset=col_names, keep=False)\n",
    "        df = df.dropna() \n",
    "        processed_dataframes[df_name] = df\n",
    "\n",
    "    return processed_dataframes\n",
    "\n",
    "def convert_to_phonemes(data_frame, remove_num=True):\n",
    "    g2p = G2p()\n",
    "\n",
    "    for df_name, df in data_frame.items():\n",
    "        df['predictions_phoneme'] = df['predictions'].apply(lambda x: \" \".join(g2p(x)))\n",
    "        df['references_phoneme'] = df['references'].apply(lambda x: \" \".join(g2p(x)))\n",
    "\n",
    "        if remove_num:\n",
    "            # Remove numeric values\n",
    "            df['predictions_phoneme'] = df['predictions_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "            df['references_phoneme'] = df['references_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "        df.drop(['predictions', 'references'], axis=1, inplace=True)\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "def split_dataframes(dataframes_word):\n",
    "    # Remove Duplicates\n",
    "    for df_name, df in dataframes_word.items():\n",
    "        # Remove rows where columns are the same\n",
    "        df = df[df['predictions_phoneme'] != df['references_phoneme']]\n",
    "        \n",
    "        # Remove rows where columns only differ by the number of spaces\n",
    "        df = df[df.apply(lambda row: row['predictions_phoneme'].strip() != row['references_phoneme'].strip(), axis=1)]\n",
    "        \n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    ori_train_dataframes_word = {}\n",
    "    test_dataframes_word = {}\n",
    "    \n",
    "    for df_name, df in dataframes_word.items():\n",
    "        # Train-Test Split\n",
    "        df = df.drop_duplicates(subset=['predictions_phoneme', 'references_phoneme'], keep=False)\n",
    "        train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "        \n",
    "        # Naming variables without pattern\n",
    "        train_df_name = df_name\n",
    "        test_df_name = f\"{df_name}_test\"\n",
    "        \n",
    "        ori_train_dataframes_word[train_df_name] = train_df\n",
    "        test_dataframes_word[test_df_name] = test_df\n",
    "    \n",
    "    train_dataframes_word = {}\n",
    "    val_dataframes_word = {} \n",
    "    \n",
    "    for df_name, df in ori_train_dataframes_word.items():\n",
    "        df = df.drop_duplicates(subset=['predictions_phoneme', 'references_phoneme'], keep=False)\n",
    "        train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "        train_df_name = f\"{df_name}_train\"\n",
    "        val_df_name = f\"{df_name}_val\"\n",
    "        \n",
    "        train_dataframes_word[train_df_name] = train_df\n",
    "        val_dataframes_word[val_df_name] = val_df\n",
    "    print_dataframe_sizes(train_dataframes_word)\n",
    "    print_dataframe_sizes(val_dataframes_word)\n",
    "    print_dataframe_sizes(test_dataframes_word)\n",
    " \n",
    "    return train_dataframes_word, val_dataframes_word, test_dataframes_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4edbb86-4ac4-4588-a085-519b3b9b6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_word_keep_all = process_dataframes(dataframes_word_keep_all, col_names)\n",
    "dataframes_sentence_keep_all = process_dataframes(dataframes_sentence_keep_all, col_names)\n",
    "dataframes_word_no_keep_all = process_dataframes(dataframes_word_no_keep_all, col_names)\n",
    "dataframes_sentence_no_keep_all = process_dataframes(dataframes_sentence_no_keep_all, col_names)\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_no_keep_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3bb03-2f66-4334-a0d3-fb0b56b0c9b4",
   "metadata": {},
   "source": [
    "# output dont Keep ALL phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cbeeb55-2da6-4137-a085-be6e40333bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_word_no_keep_all = convert_to_phonemes(dataframes_word_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edce4394-160f-4fe2-8548-7e9d93d96fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_train - Data Size: 228\n",
      "torgo_xlsr_finetune_F03_train - Data Size: 264\n",
      "torgo_xlsr_finetune_F04_train - Data Size: 256\n",
      "torgo_xlsr_finetune_M01_train - Data Size: 271\n",
      "torgo_xlsr_finetune_M02_train - Data Size: 318\n",
      "torgo_xlsr_finetune_M03_train - Data Size: 213\n",
      "torgo_xlsr_finetune_M04_train - Data Size: 333\n",
      "torgo_xlsr_finetune_M05_train - Data Size: 311\n",
      "\n",
      "torgo_xlsr_finetune_F01_val - Data Size: 26\n",
      "torgo_xlsr_finetune_F03_val - Data Size: 30\n",
      "torgo_xlsr_finetune_F04_val - Data Size: 29\n",
      "torgo_xlsr_finetune_M01_val - Data Size: 31\n",
      "torgo_xlsr_finetune_M02_val - Data Size: 36\n",
      "torgo_xlsr_finetune_M03_val - Data Size: 24\n",
      "torgo_xlsr_finetune_M04_val - Data Size: 37\n",
      "torgo_xlsr_finetune_M05_val - Data Size: 35\n",
      "\n",
      "torgo_xlsr_finetune_F01_test - Data Size: 29\n",
      "torgo_xlsr_finetune_F03_test - Data Size: 33\n",
      "torgo_xlsr_finetune_F04_test - Data Size: 32\n",
      "torgo_xlsr_finetune_M01_test - Data Size: 34\n",
      "torgo_xlsr_finetune_M02_test - Data Size: 40\n",
      "torgo_xlsr_finetune_M03_test - Data Size: 27\n",
      "torgo_xlsr_finetune_M04_test - Data Size: 42\n",
      "torgo_xlsr_finetune_M05_test - Data Size: 39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataframes_word, val_dataframes_word, test_dataframes_word=split_dataframes(dataframes_word_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09ed0e5-ef31-40f9-9904-916645ba6609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: torgo_xlsr_finetune_F01_test\n",
      "Word Error Rate (WER): 68.32%\n",
      "Character Error Rate (CER): 55.19%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03_test\n",
      "Word Error Rate (WER): 51.64%\n",
      "Character Error Rate (CER): 39.15%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04_test\n",
      "Word Error Rate (WER): 40.54%\n",
      "Character Error Rate (CER): 31.38%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01_test\n",
      "Word Error Rate (WER): 55.64%\n",
      "Character Error Rate (CER): 43.25%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02_test\n",
      "Word Error Rate (WER): 68.92%\n",
      "Character Error Rate (CER): 54.78%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03_test\n",
      "Word Error Rate (WER): 51.55%\n",
      "Character Error Rate (CER): 42.79%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M04_test\n",
      "Word Error Rate (WER): 59.24%\n",
      "Character Error Rate (CER): 46.85%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05_test\n",
      "Word Error Rate (WER): 53.62%\n",
      "Character Error Rate (CER): 40.55%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_error_rates(dataframes, phoneme_names=['predictions', 'references']):\n",
    "    for df_name, df in dataframes.items():\n",
    "        references = df[phoneme_names[1]].tolist()\n",
    "        hypotheses = df[phoneme_names[0]].tolist()\n",
    "\n",
    "        wer_score = wer(references, hypotheses)\n",
    "        cer_score = cer(references, hypotheses)\n",
    "\n",
    "        print(f'Speaker: {df_name}')\n",
    "        print(f'Word Error Rate (WER): {wer_score:.2%}')\n",
    "        print(f'Character Error Rate (CER): {cer_score:.2%}')\n",
    "        print()\n",
    "\n",
    "calculate_error_rates(test_dataframes_word, phoneme_names=['predictions_phoneme', 'references_phoneme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aa313bf-adf5-4468-9e6d-13ccdb718de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframes_to_csv(train_dataframes, val_dataframes, test_dataframes, torgo_train_type):\n",
    "    output_folder = f'data/{torgo_train_type}'\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for df_name, train_df in train_dataframes.items():\n",
    "        train_df.to_csv(os.path.join(output_folder, f'{df_name}.csv'), index=False)\n",
    "\n",
    "    for df_name, val_df in val_dataframes.items():\n",
    "        val_df.to_csv(os.path.join(output_folder, f'{df_name}.csv'), index=False)\n",
    "\n",
    "    for df_name, test_df in test_dataframes.items():\n",
    "        test_df.to_csv(os.path.join(output_folder, f'{df_name}.csv'), index=False)\n",
    "\n",
    "def convert_csv_to_json(csv_path, json_output_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    json_data = df.to_json(orient='records')\n",
    "\n",
    "    with open(json_output_path, 'w') as json_file:\n",
    "        json_file.write(json_data)\n",
    "\n",
    "TORGO_TRAIN_TYPE=TorgoTrainType.WORD_NO_KEEP.value\n",
    "save_dataframes_to_csv(train_dataframes_word, \n",
    "                       val_dataframes_word, \n",
    "                       test_dataframes_word, \n",
    "                       TORGO_TRAIN_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14a37034-2841-4bc8-a553-d655bfbfcaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "csv_folder = f'data/{TORGO_TRAIN_TYPE}'\n",
    "json_folder = f'data/{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "os.makedirs(json_folder, exist_ok=True)\n",
    "\n",
    "for csv_file_name in os.listdir(csv_folder):\n",
    "    if csv_file_name.endswith('.csv'):\n",
    "        csv_file_path = os.path.join(csv_folder, csv_file_name)\n",
    "        json_file_name = csv_file_name.replace('.csv', '.json')\n",
    "        json_output_file_path = os.path.join(json_folder, json_file_name)\n",
    "\n",
    "        convert_csv_to_json(csv_file_path, json_output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a9adf-5030-4b92-9b9a-a4815bde7e2a",
   "metadata": {},
   "source": [
    "# output Keep ALL phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9ff8720-ef11-4b7b-bea1-ecfe3436fe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_keep_all_train - Data Size: 257\n",
      "torgo_xlsr_finetune_F03_keep_all_train - Data Size: 251\n",
      "torgo_xlsr_finetune_F04_keep_all_train - Data Size: 225\n",
      "torgo_xlsr_finetune_M01_keep_all_train - Data Size: 299\n",
      "torgo_xlsr_finetune_M02_keep_all_train - Data Size: 420\n",
      "torgo_xlsr_finetune_M03_keep_all_train - Data Size: 226\n",
      "torgo_xlsr_finetune_M04__keep_all_train - Data Size: 340\n",
      "torgo_xlsr_finetune_M05_keep_all_train - Data Size: 348\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all_val - Data Size: 29\n",
      "torgo_xlsr_finetune_F03_keep_all_val - Data Size: 28\n",
      "torgo_xlsr_finetune_F04_keep_all_val - Data Size: 26\n",
      "torgo_xlsr_finetune_M01_keep_all_val - Data Size: 34\n",
      "torgo_xlsr_finetune_M02_keep_all_val - Data Size: 47\n",
      "torgo_xlsr_finetune_M03_keep_all_val - Data Size: 26\n",
      "torgo_xlsr_finetune_M04__keep_all_val - Data Size: 38\n",
      "torgo_xlsr_finetune_M05_keep_all_val - Data Size: 39\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all_test - Data Size: 32\n",
      "torgo_xlsr_finetune_F03_keep_all_test - Data Size: 32\n",
      "torgo_xlsr_finetune_F04_keep_all_test - Data Size: 28\n",
      "torgo_xlsr_finetune_M01_keep_all_test - Data Size: 37\n",
      "torgo_xlsr_finetune_M02_keep_all_test - Data Size: 52\n",
      "torgo_xlsr_finetune_M03_keep_all_test - Data Size: 28\n",
      "torgo_xlsr_finetune_M04__keep_all_test - Data Size: 42\n",
      "torgo_xlsr_finetune_M05_keep_all_test - Data Size: 43\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F01_keep_all_test\n",
      "Word Error Rate (WER): 63.37%\n",
      "Character Error Rate (CER): 45.97%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03_keep_all_test\n",
      "Word Error Rate (WER): 63.06%\n",
      "Character Error Rate (CER): 50.00%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04_keep_all_test\n",
      "Word Error Rate (WER): 68.13%\n",
      "Character Error Rate (CER): 53.68%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01_keep_all_test\n",
      "Word Error Rate (WER): 70.16%\n",
      "Character Error Rate (CER): 54.75%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02_keep_all_test\n",
      "Word Error Rate (WER): 66.67%\n",
      "Character Error Rate (CER): 49.28%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03_keep_all_test\n",
      "Word Error Rate (WER): 64.52%\n",
      "Character Error Rate (CER): 50.77%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M04__keep_all_test\n",
      "Word Error Rate (WER): 65.62%\n",
      "Character Error Rate (CER): 51.16%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05_keep_all_test\n",
      "Word Error Rate (WER): 61.59%\n",
      "Character Error Rate (CER): 53.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TORGO_TRAIN_TYPE=TorgoTrainType.WORD_KEEP.value\n",
    "dataframes_word_keep_all = convert_to_phonemes(dataframes_word_keep_all)\n",
    "train_dataframes_word, val_dataframes_word, test_dataframes_word=split_dataframes(dataframes_word_keep_all)\n",
    "calculate_error_rates(test_dataframes_word, phoneme_names=['predictions_phoneme', 'references_phoneme'])\n",
    "save_dataframes_to_csv(train_dataframes_word, \n",
    "                       val_dataframes_word, \n",
    "                       test_dataframes_word, \n",
    "                       TORGO_TRAIN_TYPE)\n",
    "csv_folder = f'data/{TORGO_TRAIN_TYPE}'\n",
    "json_folder = f'data/{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "os.makedirs(json_folder, exist_ok=True)\n",
    "\n",
    "for csv_file_name in os.listdir(csv_folder):\n",
    "    if csv_file_name.endswith('.csv'):\n",
    "        csv_file_path = os.path.join(csv_folder, csv_file_name)\n",
    "        json_file_name = csv_file_name.replace('.csv', '.json')\n",
    "        json_output_file_path = os.path.join(json_folder, json_file_name)\n",
    "\n",
    "        convert_csv_to_json(csv_file_path, json_output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7304e8-644d-4b9b-82bb-163b14e7e620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
