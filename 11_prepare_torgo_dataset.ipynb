{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c0b232a-98b1-4802-8638-52944a6ebb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/torch/cuda/__init__.py:740: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25.0\n"
     ]
    }
   ],
   "source": [
    "%run 00_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb5b1d9-2835-40f2-b674-62f9089b326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_keep_all = {}\n",
    "dataframes_no_keep_all = {}\n",
    "\n",
    "for speaker_dir in os.listdir('results'):\n",
    "    if os.path.isdir(os.path.join('results', speaker_dir)) and not speaker_dir.endswith('.ipynb_checkpoints'):\n",
    "        # speaker_dir = speaker_dir.rstrip('_')\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "        valid_df = None\n",
    "\n",
    "        for file in os.listdir(os.path.join('results', speaker_dir)):\n",
    "            if file.endswith('.csv'):\n",
    "                df_name = os.path.splitext(file)[0]\n",
    "                df_path = os.path.join('results', speaker_dir, file)\n",
    "                \n",
    "                if 'train' in df_name:\n",
    "                    if train_df is None:\n",
    "                        train_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'test' in df_name:\n",
    "                    if test_df is None:\n",
    "                        test_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'validation' in df_name:\n",
    "                    if valid_df is None:\n",
    "                        valid_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "        \n",
    "        combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        if 'keep_all' in speaker_dir:\n",
    "            dataframes_keep_all[speaker_dir] = combined_df\n",
    "        else:\n",
    "            dataframes_no_keep_all[speaker_dir] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180e1843-1000-4e98-92d1-1ba07cd797e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_keep_all = {}\n",
    "dataframes_no_keep_all = {}\n",
    "\n",
    "for speaker_dir in os.listdir('results'):\n",
    "    if os.path.isdir(os.path.join('results', speaker_dir)) and not speaker_dir.endswith('.ipynb_checkpoints'):\n",
    "        # speaker_dir = speaker_dir.rstrip('_')\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "        valid_df = None\n",
    "\n",
    "        for file in os.listdir(os.path.join('results', speaker_dir)):\n",
    "            if file.endswith('.csv'):\n",
    "                df_name = os.path.splitext(file)[0]\n",
    "                df_path = os.path.join('results', speaker_dir, file)\n",
    "                \n",
    "                if 'train' in df_name:\n",
    "                    if train_df is None:\n",
    "                        train_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'test' in df_name:\n",
    "                    if test_df is None:\n",
    "                        test_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'validation' in df_name:\n",
    "                    if valid_df is None:\n",
    "                        valid_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "        \n",
    "        combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        if 'keep_all' in speaker_dir:\n",
    "            dataframes_keep_all[speaker_dir] = combined_df\n",
    "        else:\n",
    "            dataframes_no_keep_all[speaker_dir] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56941ce1-5050-4bf6-b9cb-72c0c74e3a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_M04 - Data Size: 11751\n",
      "torgo_xlsr_finetune_M02 - Data Size: 9790\n",
      "torgo_xlsr_finetune_F03 - Data Size: 8568\n",
      "torgo_xlsr_finetune_M05 - Data Size: 8853\n",
      "torgo_xlsr_finetune_M03 - Data Size: 9572\n",
      "torgo_xlsr_finetune_F01 - Data Size: 14409\n",
      "torgo_xlsr_finetune_M01 - Data Size: 6540\n",
      "torgo_xlsr_finetune_F04 - Data Size: 9454\n",
      "\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 16082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_dataframe_sizes(dataframes_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb2b4bf-d842-49a3-9b7a-81fb1690c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 12115\n",
      "\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 3967\n",
      "\n",
      "torgo_xlsr_finetune_M04 - Data Size: 9139\n",
      "torgo_xlsr_finetune_M02 - Data Size: 7687\n",
      "torgo_xlsr_finetune_F03 - Data Size: 6813\n",
      "torgo_xlsr_finetune_M05 - Data Size: 7178\n",
      "torgo_xlsr_finetune_M03 - Data Size: 7480\n",
      "torgo_xlsr_finetune_F01 - Data Size: 10795\n",
      "torgo_xlsr_finetune_M01 - Data Size: 4404\n",
      "torgo_xlsr_finetune_F04 - Data Size: 7482\n",
      "\n",
      "torgo_xlsr_finetune_M04 - Data Size: 2612\n",
      "torgo_xlsr_finetune_M02 - Data Size: 2103\n",
      "torgo_xlsr_finetune_F03 - Data Size: 1755\n",
      "torgo_xlsr_finetune_M05 - Data Size: 1675\n",
      "torgo_xlsr_finetune_M03 - Data Size: 2092\n",
      "torgo_xlsr_finetune_F01 - Data Size: 3614\n",
      "torgo_xlsr_finetune_M01 - Data Size: 2136\n",
      "torgo_xlsr_finetune_F04 - Data Size: 1972\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_134301/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all = {}\n",
    "dataframes_sentence_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "dataframes_word_no_keep_all = {}\n",
    "dataframes_sentence_no_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_no_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_no_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_no_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fdcd6b-1eee-49b5-b87f-a926d0fe5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def process_dataframes(dataframes_dict, col_names):\n",
    "    processed_dataframes = {}\n",
    "\n",
    "    for df_name, df in dataframes_dict.items():\n",
    "        # Remove duplicates and drop NaN values\n",
    "        df = df.drop_duplicates(subset=col_names, keep=False)\n",
    "        df = df.dropna() \n",
    "        processed_dataframes[df_name] = df\n",
    "\n",
    "    return processed_dataframes\n",
    "\n",
    "def convert_to_phonemes(data_frame, remove_num=True):\n",
    "    g2p = G2p()\n",
    "\n",
    "    for df_name, df in data_frame.items():\n",
    "        df['predictions_phoneme'] = df['predictions'].apply(lambda x: \" \".join(g2p(x)))\n",
    "        df['references_phoneme'] = df['references'].apply(lambda x: \" \".join(g2p(x)))\n",
    "\n",
    "        if remove_num:\n",
    "            # Remove numeric values\n",
    "            df['predictions_phoneme'] = df['predictions_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "            df['references_phoneme'] = df['references_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "        df.drop(['predictions', 'references'], axis=1, inplace=True)\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "def split_dataframes(dataframes_word):\n",
    "    train_dataframes_word = {}\n",
    "    test_dataframes_word = {}\n",
    "\n",
    "    for df_name, df in dataframes_word.items():\n",
    "        # Remove Duplicates\n",
    "        df = df[df['predictions_phoneme'] != df['references_phoneme']]\n",
    "        \n",
    "        # Remove rows where columns only differ by the number of spaces\n",
    "        df = df[df.apply(lambda row: row['predictions_phoneme'].strip() != row['references_phoneme'].strip(), axis=1)]\n",
    "        \n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Train-Test Split\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Naming variables without pattern\n",
    "        train_df_name = f\"{df_name}_train\"\n",
    "        test_df_name = f\"{df_name}_test\"\n",
    "        \n",
    "        train_dataframes_word[train_df_name] = train_df\n",
    "        test_dataframes_word[test_df_name] = test_df\n",
    "    \n",
    "    print_dataframe_sizes(train_dataframes_word)\n",
    "    print_dataframe_sizes(test_dataframes_word)\n",
    " \n",
    "    return train_dataframes_word, test_dataframes_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a62a541-dfb2-4d31-b030-b48f0046d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 296\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 534\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 452\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 449\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 328\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 336\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 288\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 399\n",
      "\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 236\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 355\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 273\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 270\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 229\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 239\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 223\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 336\n",
      "\n",
      "torgo_xlsr_finetune_M04 - Data Size: 432\n",
      "torgo_xlsr_finetune_M02 - Data Size: 405\n",
      "torgo_xlsr_finetune_F03 - Data Size: 356\n",
      "torgo_xlsr_finetune_M05 - Data Size: 404\n",
      "torgo_xlsr_finetune_M03 - Data Size: 285\n",
      "torgo_xlsr_finetune_F01 - Data Size: 305\n",
      "torgo_xlsr_finetune_M01 - Data Size: 352\n",
      "torgo_xlsr_finetune_F04 - Data Size: 340\n",
      "\n",
      "torgo_xlsr_finetune_M04 - Data Size: 223\n",
      "torgo_xlsr_finetune_M02 - Data Size: 256\n",
      "torgo_xlsr_finetune_F03 - Data Size: 317\n",
      "torgo_xlsr_finetune_M05 - Data Size: 149\n",
      "torgo_xlsr_finetune_M03 - Data Size: 242\n",
      "torgo_xlsr_finetune_F01 - Data Size: 217\n",
      "torgo_xlsr_finetune_M01 - Data Size: 239\n",
      "torgo_xlsr_finetune_F04 - Data Size: 243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all = process_dataframes(dataframes_word_keep_all, col_names)\n",
    "dataframes_sentence_keep_all = process_dataframes(dataframes_sentence_keep_all, col_names)\n",
    "dataframes_word_no_keep_all = process_dataframes(dataframes_word_no_keep_all, col_names)\n",
    "dataframes_sentence_no_keep_all = process_dataframes(dataframes_sentence_no_keep_all, col_names)\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_no_keep_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11263227",
   "metadata": {},
   "source": [
    "# output no keep overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbb07a9-a31e-493a-bb35-349b6f3f055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_word_no_keep_all_phoneme = convert_to_phonemes(dataframes_word_no_keep_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b158f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_M04 - Data Size: 432\n",
      "torgo_xlsr_finetune_M02 - Data Size: 405\n",
      "torgo_xlsr_finetune_F03 - Data Size: 356\n",
      "torgo_xlsr_finetune_M05 - Data Size: 404\n",
      "torgo_xlsr_finetune_M03 - Data Size: 285\n",
      "torgo_xlsr_finetune_F01 - Data Size: 305\n",
      "torgo_xlsr_finetune_M01 - Data Size: 352\n",
      "torgo_xlsr_finetune_F04 - Data Size: 340\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'torgo_xlsr_finetune_M04':       predictions_phoneme references_phoneme\n",
       " 143              S W IY T           S W IY T\n",
       " 170                  F AY             F AO R\n",
       " 603                R AY T             R AY T\n",
       " 684                  EY P               EY T\n",
       " 1411                HH AA            HH AO L\n",
       " ...                   ...                ...\n",
       " 11742              R EY K             L EY K\n",
       " 11743              T IH P             Z IH P\n",
       " 11744            N AH S T           N EH S T\n",
       " 11745             R EH JH             R AY D\n",
       " 11748      S AW TH IY S T             S EH L\n",
       " \n",
       " [432 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M02':      predictions_phoneme references_phoneme\n",
       " 69                S IY T            SH IY T\n",
       " 115               R AY T             R AY T\n",
       " 144             S W IY T           S W IY T\n",
       " 170      F L AO R L AO R             F AO R\n",
       " 377               R AY T             R AY T\n",
       " ...                  ...                ...\n",
       " 9760            G R IY F             L IY K\n",
       " 9764            D AA R S             D AY S\n",
       " 9772             HH IY P              HH IY\n",
       " 9784            N UW S T           N EH S T\n",
       " 9785          R AH JH IY             R AY D\n",
       " \n",
       " [405 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_F03':      predictions_phoneme references_phoneme\n",
       " 493               EY G T               EY T\n",
       " 780                HH AA            HH AO L\n",
       " 1375             EY T IY               EY T\n",
       " 1773                AY T               EY T\n",
       " 1808          S P L IH T         S P L IH T\n",
       " ...                  ...                ...\n",
       " 8416              B AE T             F AE T\n",
       " 8486   S AY G OW F IH SH               S AY\n",
       " 8490           F UH R UW           F L AO R\n",
       " 8492              R AY T             R AY T\n",
       " 8527                IY T               EY T\n",
       " \n",
       " [356 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M05':      predictions_phoneme references_phoneme\n",
       " 7             S T AO R M         S T AO R M\n",
       " 134               IY G T               EY T\n",
       " 145             S W IY T           S W IY T\n",
       " 171            F UH R AW             F AO R\n",
       " 292                HH AY            HH IH M\n",
       " ...                  ...                ...\n",
       " 8830            G R IY K             L IY K\n",
       " 8832              D ER K             D AY S\n",
       " 8838             HH IY P              HH IY\n",
       " 8848              R AH G             R AY D\n",
       " 8850                S OW             S EH L\n",
       " \n",
       " [404 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M03':      predictions_phoneme references_phoneme\n",
       " 150             S W IY T           S W IY T\n",
       " 154                 EY T               EY T\n",
       " 176               F AW R             F AO R\n",
       " 312              HH AH M            HH IH M\n",
       " 933               EY G T               EY T\n",
       " ...                  ...                ...\n",
       " 9545                R IY             L IY K\n",
       " 9546              L EY K             R EH D\n",
       " 9554             SH AY P              HH IY\n",
       " 9565             SH IH P             Z IH P\n",
       " 9567          HH R UW JH             R AY D\n",
       " \n",
       " [285 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_F01':       predictions_phoneme references_phoneme\n",
       " 84               S W IY T           S W IY T\n",
       " 175             F ER F ER             F AO R\n",
       " 342                R AY T             R AY T\n",
       " 581                  IH M            HH IH M\n",
       " 649                R AY T             R AY T\n",
       " ...                   ...                ...\n",
       " 14373              L IH K             R EH D\n",
       " 14384             HH IY P              HH IY\n",
       " 14401                IH P             Z IH P\n",
       " 14402            M AH S T           N EH S T\n",
       " 14403             R AY JH             R AY D\n",
       " \n",
       " [305 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_M01':      predictions_phoneme references_phoneme\n",
       " 12              S W IY T           S W IY T\n",
       " 2030             OW K EY            OW K EY\n",
       " 2182                  IY             M AY L\n",
       " 2441       R IH L AE K S      R IH L AE K S\n",
       " 2570              L IH S        W IH S K IY\n",
       " ...                  ...                ...\n",
       " 6527             HH AY P              HH IY\n",
       " 6530                F OW               F OW\n",
       " 6536                IH P             Z IH P\n",
       " 6537            M ER S T           N EH S T\n",
       " 6538             R UW JH             R AY D\n",
       " \n",
       " [352 rows x 2 columns],\n",
       " 'torgo_xlsr_finetune_F04':      predictions_phoneme references_phoneme\n",
       " 272               EY G T               EY T\n",
       " 275                 EY P               EY T\n",
       " 699               IY G T               EY T\n",
       " 953             P AE S T           P EY S T\n",
       " 1506                AE D               AE D\n",
       " ...                  ...                ...\n",
       " 9429              L EH D             R EH D\n",
       " 9438             HH IH T              HH IY\n",
       " 9443              S AY T             S AY D\n",
       " 9448              R EY K             L EY K\n",
       " 9449              R AH D             R AY D\n",
       " \n",
       " [340 rows x 2 columns]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_dataframe_sizes(dataframes_word_no_keep_all_phoneme)\n",
    "dataframes_word_no_keep_all_phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cf7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3208bf47-d0d2-4741-83f5-956b30dbe113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: torgo_xlsr_finetune_M04\n",
      "Word Error Rate (WER): 65.13%\n",
      "Character Error Rate (CER): 51.36%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02\n",
      "Word Error Rate (WER): 67.27%\n",
      "Character Error Rate (CER): 53.43%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03\n",
      "Word Error Rate (WER): 58.56%\n",
      "Character Error Rate (CER): 47.25%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05\n",
      "Word Error Rate (WER): 62.54%\n",
      "Character Error Rate (CER): 50.13%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03\n",
      "Word Error Rate (WER): 50.70%\n",
      "Character Error Rate (CER): 39.61%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F01\n",
      "Word Error Rate (WER): 59.48%\n",
      "Character Error Rate (CER): 47.36%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01\n",
      "Word Error Rate (WER): 54.05%\n",
      "Character Error Rate (CER): 40.99%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04\n",
      "Word Error Rate (WER): 45.04%\n",
      "Character Error Rate (CER): 35.82%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_error_rates(dataframes, phoneme_names=['predictions', 'references']):\n",
    "    for df_name, df in dataframes.items():\n",
    "        references = df[phoneme_names[1]].tolist()\n",
    "        hypotheses = df[phoneme_names[0]].tolist()\n",
    "\n",
    "        wer_score = wer(references, hypotheses)\n",
    "        cer_score = cer(references, hypotheses)\n",
    "\n",
    "        print(f'Speaker: {df_name}')\n",
    "        print(f'Word Error Rate (WER): {wer_score:.2%}')\n",
    "        print(f'Character Error Rate (CER): {cer_score:.2%}')\n",
    "        print()\n",
    "\n",
    "calculate_error_rates(dataframes_word_no_keep_all_phoneme, phoneme_names=['predictions_phoneme', 'references_phoneme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8f8f2e-8955-49c5-ab0d-8e95983aca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORGO_TRAIN_TYPE = TorgoTrainType.WORD_NO_KEEP.value\n",
    "OUT_DIR = f'data/kenlm_{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "# Check if OUT_DIR exists, if not, create it\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for df_name, df in train_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names\n",
    "\n",
    "for df_name, df in test_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28446b34-1d32-456d-968e-1efc44fa239d",
   "metadata": {},
   "source": [
    "# output Keep ALL phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "855c583d-b45a-4250-9f31-a5b33e8dad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F04_keep_all_train - Data Size: 220\n",
      "torgo_xlsr_finetune_M02_keep_all_train - Data Size: 409\n",
      "torgo_xlsr_finetune_M05_keep_all_train - Data Size: 347\n",
      "torgo_xlsr_finetune_M04__keep_all_train - Data Size: 343\n",
      "torgo_xlsr_finetune_F03_keep_all_train - Data Size: 242\n",
      "torgo_xlsr_finetune_F01_keep_all_train - Data Size: 257\n",
      "torgo_xlsr_finetune_M03_keep_all_train - Data Size: 218\n",
      "torgo_xlsr_finetune_M01_keep_all_train - Data Size: 304\n",
      "\n",
      "torgo_xlsr_finetune_F04_keep_all_test - Data Size: 56\n",
      "torgo_xlsr_finetune_M02_keep_all_test - Data Size: 103\n",
      "torgo_xlsr_finetune_M05_keep_all_test - Data Size: 87\n",
      "torgo_xlsr_finetune_M04__keep_all_test - Data Size: 86\n",
      "torgo_xlsr_finetune_F03_keep_all_test - Data Size: 61\n",
      "torgo_xlsr_finetune_F01_keep_all_test - Data Size: 65\n",
      "torgo_xlsr_finetune_M03_keep_all_test - Data Size: 55\n",
      "torgo_xlsr_finetune_M01_keep_all_test - Data Size: 77\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04_keep_all_test\n",
      "Word Error Rate (WER): 76.00%\n",
      "Character Error Rate (CER): 64.75%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02_keep_all_test\n",
      "Word Error Rate (WER): 68.59%\n",
      "Character Error Rate (CER): 51.24%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05_keep_all_test\n",
      "Word Error Rate (WER): 61.51%\n",
      "Character Error Rate (CER): 47.38%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M04__keep_all_test\n",
      "Word Error Rate (WER): 60.71%\n",
      "Character Error Rate (CER): 44.92%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03_keep_all_test\n",
      "Word Error Rate (WER): 63.10%\n",
      "Character Error Rate (CER): 48.33%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F01_keep_all_test\n",
      "Word Error Rate (WER): 64.47%\n",
      "Character Error Rate (CER): 47.59%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03_keep_all_test\n",
      "Word Error Rate (WER): 73.16%\n",
      "Character Error Rate (CER): 59.31%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01_keep_all_test\n",
      "Word Error Rate (WER): 69.70%\n",
      "Character Error Rate (CER): 56.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TORGO_TRAIN_TYPE=TorgoTrainType.WORD_KEEP.value\n",
    "dataframes_word_keep_all_phoneme = convert_to_phonemes(dataframes_word_keep_all)\n",
    "train_dataframes_word, test_dataframes_word=split_dataframes(dataframes_word_keep_all_phoneme)\n",
    "calculate_error_rates(test_dataframes_word, phoneme_names=['predictions_phoneme', 'references_phoneme'])\n",
    "\n",
    "OUT_DIR = f'data/kenlm_{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "# Check if OUT_DIR exists, if not, create it\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for df_name, df in train_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names\n",
    "\n",
    "for df_name, df in test_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c66f0-fdc3-4361-b375-661fb0c1e117",
   "metadata": {},
   "source": [
    "# PREPARE SUPERVISED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e60320-0766-42e4-9249-216a6c5c1146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
