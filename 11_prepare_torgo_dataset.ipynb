{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0b232a-98b1-4802-8638-52944a6ebb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27.0\n"
     ]
    }
   ],
   "source": [
    "%run 00_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb5b1d9-2835-40f2-b674-62f9089b326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_keep_all = {}\n",
    "dataframes_no_keep_all = {}\n",
    "\n",
    "for speaker_dir in os.listdir('results'):\n",
    "    if os.path.isdir(os.path.join('results', speaker_dir)) and not speaker_dir.endswith('.ipynb_checkpoints'):\n",
    "        # speaker_dir = speaker_dir.rstrip('_')\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "        valid_df = None\n",
    "\n",
    "        for file in os.listdir(os.path.join('results', speaker_dir)):\n",
    "            if file.endswith('.csv'):\n",
    "                df_name = os.path.splitext(file)[0]\n",
    "                df_path = os.path.join('results', speaker_dir, file)\n",
    "                \n",
    "                if 'train' in df_name:\n",
    "                    if train_df is None:\n",
    "                        train_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'test' in df_name:\n",
    "                    if test_df is None:\n",
    "                        test_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'validation' in df_name:\n",
    "                    if valid_df is None:\n",
    "                        valid_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "        \n",
    "        combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        if 'keep_all' in speaker_dir:\n",
    "            dataframes_keep_all[speaker_dir] = combined_df\n",
    "        else:\n",
    "            dataframes_no_keep_all[speaker_dir] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180e1843-1000-4e98-92d1-1ba07cd797e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_keep_all = {}\n",
    "dataframes_no_keep_all = {}\n",
    "\n",
    "for speaker_dir in os.listdir('results'):\n",
    "    if os.path.isdir(os.path.join('results', speaker_dir)) and not speaker_dir.endswith('.ipynb_checkpoints'):\n",
    "        # speaker_dir = speaker_dir.rstrip('_')\n",
    "        train_df = None\n",
    "        test_df = None\n",
    "        valid_df = None\n",
    "\n",
    "        for file in os.listdir(os.path.join('results', speaker_dir)):\n",
    "            if file.endswith('.csv'):\n",
    "                df_name = os.path.splitext(file)[0]\n",
    "                df_path = os.path.join('results', speaker_dir, file)\n",
    "                \n",
    "                if 'train' in df_name:\n",
    "                    if train_df is None:\n",
    "                        train_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        train_df = pd.concat([train_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'test' in df_name:\n",
    "                    if test_df is None:\n",
    "                        test_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        test_df = pd.concat([test_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "                elif 'validation' in df_name:\n",
    "                    if valid_df is None:\n",
    "                        valid_df = pd.read_csv(df_path)\n",
    "                    else:\n",
    "                        valid_df = pd.concat([valid_df, pd.read_csv(df_path)], ignore_index=True)\n",
    "        \n",
    "        combined_df = pd.concat([train_df, test_df, valid_df], ignore_index=True)\n",
    "        \n",
    "        if 'keep_all' in speaker_dir:\n",
    "            dataframes_keep_all[speaker_dir] = combined_df\n",
    "        else:\n",
    "            dataframes_no_keep_all[speaker_dir] = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56941ce1-5050-4bf6-b9cb-72c0c74e3a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01 - Data Size: 14409\n",
      "torgo_xlsr_finetune_F03 - Data Size: 8568\n",
      "torgo_xlsr_finetune_F04 - Data Size: 9454\n",
      "torgo_xlsr_finetune_M01 - Data Size: 6540\n",
      "torgo_xlsr_finetune_M02 - Data Size: 9790\n",
      "torgo_xlsr_finetune_M03 - Data Size: 9572\n",
      "torgo_xlsr_finetune_M04 - Data Size: 11751\n",
      "torgo_xlsr_finetune_M05 - Data Size: 8853\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M04_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 16082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_dataframe_sizes(dataframes_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adb2b4bf-d842-49a3-9b7a-81fb1690c84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 12115\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M04_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 12129\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 3967\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M04_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 3953\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 10795\n",
      "torgo_xlsr_finetune_F03 - Data Size: 6813\n",
      "torgo_xlsr_finetune_F04 - Data Size: 7482\n",
      "torgo_xlsr_finetune_M01 - Data Size: 4404\n",
      "torgo_xlsr_finetune_M02 - Data Size: 7687\n",
      "torgo_xlsr_finetune_M03 - Data Size: 7480\n",
      "torgo_xlsr_finetune_M04 - Data Size: 9139\n",
      "torgo_xlsr_finetune_M05 - Data Size: 7178\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 3614\n",
      "torgo_xlsr_finetune_F03 - Data Size: 1755\n",
      "torgo_xlsr_finetune_F04 - Data Size: 1972\n",
      "torgo_xlsr_finetune_M01 - Data Size: 2136\n",
      "torgo_xlsr_finetune_M02 - Data Size: 2103\n",
      "torgo_xlsr_finetune_M03 - Data Size: 2092\n",
      "torgo_xlsr_finetune_M04 - Data Size: 2612\n",
      "torgo_xlsr_finetune_M05 - Data Size: 1675\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_32821/2810713955.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all = {}\n",
    "dataframes_sentence_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "dataframes_word_no_keep_all = {}\n",
    "dataframes_sentence_no_keep_all = {}\n",
    "\n",
    "for speaker_dir, combined_df in dataframes_no_keep_all.items():\n",
    "    combined_df['word_count'] = combined_df['references'].str.split().apply(len)\n",
    "    word_df = combined_df[combined_df['word_count'] == 1]\n",
    "    sentence_df = combined_df[combined_df['word_count'] > 1]\n",
    "    word_df.drop(columns=['word_count'], inplace=True)\n",
    "    sentence_df.drop(columns=['word_count'], inplace=True)\n",
    "    dataframes_word_no_keep_all[speaker_dir] = word_df\n",
    "    dataframes_sentence_no_keep_all[speaker_dir] = sentence_df\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41fdcd6b-1eee-49b5-b87f-a926d0fe5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def process_dataframes(dataframes_dict, col_names):\n",
    "    processed_dataframes = {}\n",
    "\n",
    "    for df_name, df in dataframes_dict.items():\n",
    "        # Remove duplicates and drop NaN values\n",
    "        df = df.drop_duplicates(subset=col_names, keep=False)\n",
    "        df = df.dropna() \n",
    "        processed_dataframes[df_name] = df\n",
    "\n",
    "    return processed_dataframes\n",
    "\n",
    "def convert_to_phonemes(data_frame, remove_num=True):\n",
    "    g2p = G2p()\n",
    "\n",
    "    for df_name, df in data_frame.items():\n",
    "        df['predictions_phoneme'] = df['predictions'].apply(lambda x: \" \".join(g2p(x)))\n",
    "        df['references_phoneme'] = df['references'].apply(lambda x: \" \".join(g2p(x)))\n",
    "\n",
    "        if remove_num:\n",
    "            # Remove numeric values\n",
    "            df['predictions_phoneme'] = df['predictions_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "            df['references_phoneme'] = df['references_phoneme'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "        df.drop(['predictions', 'references'], axis=1, inplace=True)\n",
    "\n",
    "    return data_frame\n",
    "\n",
    "def split_dataframes(dataframes_word):\n",
    "    train_dataframes_word = {}\n",
    "    test_dataframes_word = {}\n",
    "\n",
    "    for df_name, df in dataframes_word.items():\n",
    "        # Remove Duplicates\n",
    "        df = df[df['predictions_phoneme'] != df['references_phoneme']]\n",
    "        \n",
    "        # Remove rows where columns only differ by the number of spaces\n",
    "        df = df[df.apply(lambda row: row['predictions_phoneme'].strip() != row['references_phoneme'].strip(), axis=1)]\n",
    "        \n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Train-Test Split\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Naming variables without pattern\n",
    "        train_df_name = f\"{df_name}_train\"\n",
    "        test_df_name = f\"{df_name}_test\"\n",
    "        \n",
    "        train_dataframes_word[train_df_name] = train_df\n",
    "        test_dataframes_word[test_df_name] = test_df\n",
    "    \n",
    "    print_dataframe_sizes(train_dataframes_word)\n",
    "    print_dataframe_sizes(test_dataframes_word)\n",
    " \n",
    "    return train_dataframes_word, test_dataframes_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a62a541-dfb2-4d31-b030-b48f0046d2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 336\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 328\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 296\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 399\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 534\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 288\n",
      "torgo_xlsr_finetune_M04_keep_all - Data Size: 449\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 452\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 239\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 229\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 236\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 336\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 355\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 223\n",
      "torgo_xlsr_finetune_M04_keep_all - Data Size: 270\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 273\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 305\n",
      "torgo_xlsr_finetune_F03 - Data Size: 356\n",
      "torgo_xlsr_finetune_F04 - Data Size: 340\n",
      "torgo_xlsr_finetune_M01 - Data Size: 352\n",
      "torgo_xlsr_finetune_M02 - Data Size: 405\n",
      "torgo_xlsr_finetune_M03 - Data Size: 285\n",
      "torgo_xlsr_finetune_M04 - Data Size: 432\n",
      "torgo_xlsr_finetune_M05 - Data Size: 404\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 217\n",
      "torgo_xlsr_finetune_F03 - Data Size: 317\n",
      "torgo_xlsr_finetune_F04 - Data Size: 243\n",
      "torgo_xlsr_finetune_M01 - Data Size: 239\n",
      "torgo_xlsr_finetune_M02 - Data Size: 256\n",
      "torgo_xlsr_finetune_M03 - Data Size: 242\n",
      "torgo_xlsr_finetune_M04 - Data Size: 223\n",
      "torgo_xlsr_finetune_M05 - Data Size: 149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframes_word_keep_all = process_dataframes(dataframes_word_keep_all, col_names)\n",
    "dataframes_sentence_keep_all = process_dataframes(dataframes_sentence_keep_all, col_names)\n",
    "dataframes_word_no_keep_all = process_dataframes(dataframes_word_no_keep_all, col_names)\n",
    "dataframes_sentence_no_keep_all = process_dataframes(dataframes_sentence_no_keep_all, col_names)\n",
    "\n",
    "print_dataframe_sizes(dataframes_word_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_keep_all)\n",
    "print_dataframe_sizes(dataframes_word_no_keep_all)\n",
    "print_dataframe_sizes(dataframes_sentence_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccbb07a9-a31e-493a-bb35-349b6f3f055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_word_no_keep_all_phoneme = convert_to_phonemes(dataframes_word_no_keep_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48673c6e-dd3b-42a7-8e6e-a452d070622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_train - Data Size: 225\n",
      "torgo_xlsr_finetune_F03_train - Data Size: 247\n",
      "torgo_xlsr_finetune_F04_train - Data Size: 204\n",
      "torgo_xlsr_finetune_M01_train - Data Size: 247\n",
      "torgo_xlsr_finetune_M02_train - Data Size: 305\n",
      "torgo_xlsr_finetune_M03_train - Data Size: 190\n",
      "torgo_xlsr_finetune_M04_train - Data Size: 322\n",
      "torgo_xlsr_finetune_M05_train - Data Size: 295\n",
      "\n",
      "torgo_xlsr_finetune_F01_test - Data Size: 57\n",
      "torgo_xlsr_finetune_F03_test - Data Size: 62\n",
      "torgo_xlsr_finetune_F04_test - Data Size: 51\n",
      "torgo_xlsr_finetune_M01_test - Data Size: 62\n",
      "torgo_xlsr_finetune_M02_test - Data Size: 77\n",
      "torgo_xlsr_finetune_M03_test - Data Size: 48\n",
      "torgo_xlsr_finetune_M04_test - Data Size: 81\n",
      "torgo_xlsr_finetune_M05_test - Data Size: 74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataframes_word, test_dataframes_word=split_dataframes(dataframes_word_no_keep_all_phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3208bf47-d0d2-4741-83f5-956b30dbe113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: torgo_xlsr_finetune_F01_test\n",
      "Word Error Rate (WER): 62.00%\n",
      "Character Error Rate (CER): 48.58%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03_test\n",
      "Word Error Rate (WER): 68.35%\n",
      "Character Error Rate (CER): 53.72%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04_test\n",
      "Word Error Rate (WER): 66.10%\n",
      "Character Error Rate (CER): 50.81%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01_test\n",
      "Word Error Rate (WER): 57.58%\n",
      "Character Error Rate (CER): 44.65%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02_test\n",
      "Word Error Rate (WER): 66.17%\n",
      "Character Error Rate (CER): 53.59%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03_test\n",
      "Word Error Rate (WER): 71.17%\n",
      "Character Error Rate (CER): 61.96%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M04_test\n",
      "Word Error Rate (WER): 67.03%\n",
      "Character Error Rate (CER): 52.04%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05_test\n",
      "Word Error Rate (WER): 67.62%\n",
      "Character Error Rate (CER): 54.30%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_error_rates(dataframes, phoneme_names=['predictions', 'references']):\n",
    "    for df_name, df in dataframes.items():\n",
    "        references = df[phoneme_names[1]].tolist()\n",
    "        hypotheses = df[phoneme_names[0]].tolist()\n",
    "\n",
    "        wer_score = wer(references, hypotheses)\n",
    "        cer_score = cer(references, hypotheses)\n",
    "\n",
    "        print(f'Speaker: {df_name}')\n",
    "        print(f'Word Error Rate (WER): {wer_score:.2%}')\n",
    "        print(f'Character Error Rate (CER): {cer_score:.2%}')\n",
    "        print()\n",
    "\n",
    "calculate_error_rates(test_dataframes_word, phoneme_names=['predictions_phoneme', 'references_phoneme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c8f8f2e-8955-49c5-ab0d-8e95983aca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "TORGO_TRAIN_TYPE = TorgoTrainType.WORD_NO_KEEP.value\n",
    "OUT_DIR = f'data/kenlm_{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "# Check if OUT_DIR exists, if not, create it\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for df_name, df in train_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names\n",
    "\n",
    "for df_name, df in test_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28446b34-1d32-456d-968e-1efc44fa239d",
   "metadata": {},
   "source": [
    "# output Keep ALL phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "855c583d-b45a-4250-9f31-a5b33e8dad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_keep_all_train - Data Size: 257\n",
      "torgo_xlsr_finetune_F03_keep_all_train - Data Size: 242\n",
      "torgo_xlsr_finetune_F04_keep_all_train - Data Size: 220\n",
      "torgo_xlsr_finetune_M01_keep_all_train - Data Size: 304\n",
      "torgo_xlsr_finetune_M02_keep_all_train - Data Size: 409\n",
      "torgo_xlsr_finetune_M03_keep_all_train - Data Size: 218\n",
      "torgo_xlsr_finetune_M04_keep_all_train - Data Size: 343\n",
      "torgo_xlsr_finetune_M05_keep_all_train - Data Size: 347\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all_test - Data Size: 65\n",
      "torgo_xlsr_finetune_F03_keep_all_test - Data Size: 61\n",
      "torgo_xlsr_finetune_F04_keep_all_test - Data Size: 56\n",
      "torgo_xlsr_finetune_M01_keep_all_test - Data Size: 77\n",
      "torgo_xlsr_finetune_M02_keep_all_test - Data Size: 103\n",
      "torgo_xlsr_finetune_M03_keep_all_test - Data Size: 55\n",
      "torgo_xlsr_finetune_M04_keep_all_test - Data Size: 86\n",
      "torgo_xlsr_finetune_M05_keep_all_test - Data Size: 87\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F01_keep_all_test\n",
      "Word Error Rate (WER): 64.47%\n",
      "Character Error Rate (CER): 47.59%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F03_keep_all_test\n",
      "Word Error Rate (WER): 63.10%\n",
      "Character Error Rate (CER): 48.33%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_F04_keep_all_test\n",
      "Word Error Rate (WER): 76.00%\n",
      "Character Error Rate (CER): 64.75%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M01_keep_all_test\n",
      "Word Error Rate (WER): 69.70%\n",
      "Character Error Rate (CER): 56.89%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M02_keep_all_test\n",
      "Word Error Rate (WER): 68.59%\n",
      "Character Error Rate (CER): 51.24%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M03_keep_all_test\n",
      "Word Error Rate (WER): 73.16%\n",
      "Character Error Rate (CER): 59.31%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M04_keep_all_test\n",
      "Word Error Rate (WER): 60.71%\n",
      "Character Error Rate (CER): 44.92%\n",
      "\n",
      "Speaker: torgo_xlsr_finetune_M05_keep_all_test\n",
      "Word Error Rate (WER): 61.51%\n",
      "Character Error Rate (CER): 47.38%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TORGO_TRAIN_TYPE=TorgoTrainType.WORD_KEEP.value\n",
    "dataframes_word_keep_all_phoneme = convert_to_phonemes(dataframes_word_keep_all)\n",
    "train_dataframes_word, test_dataframes_word=split_dataframes(dataframes_word_keep_all_phoneme)\n",
    "calculate_error_rates(test_dataframes_word, phoneme_names=['predictions_phoneme', 'references_phoneme'])\n",
    "\n",
    "OUT_DIR = f'data/kenlm_{TORGO_TRAIN_TYPE}'\n",
    "\n",
    "# Check if OUT_DIR exists, if not, create it\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "for df_name, df in train_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names\n",
    "\n",
    "for df_name, df in test_dataframes_word.items():\n",
    "    file_name = f\"{df_name}_{TORGO_TRAIN_TYPE}.txt\"\n",
    "    file_path = os.path.join(OUT_DIR, file_name)\n",
    "    df.to_csv(file_path, index=False, sep='\\t', header=False)  # Set header=False to exclude column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c66f0-fdc3-4361-b375-661fb0c1e117",
   "metadata": {},
   "source": [
    "# PREPARE SUPERVISED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e60320-0766-42e4-9249-216a6c5c1146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
