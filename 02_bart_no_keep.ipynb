{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf8bba9-daa2-470c-8767-1d799b175d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_phoneme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27.0\n",
      "torgo_xlsr_finetune_F01 - Data Size: 14409\n",
      "torgo_xlsr_finetune_F03 - Data Size: 8568\n",
      "torgo_xlsr_finetune_F04 - Data Size: 9454\n",
      "torgo_xlsr_finetune_M01 - Data Size: 6540\n",
      "torgo_xlsr_finetune_M02 - Data Size: 9790\n",
      "torgo_xlsr_finetune_M03 - Data Size: 9572\n",
      "torgo_xlsr_finetune_M04 - Data Size: 11751\n",
      "torgo_xlsr_finetune_M05 - Data Size: 8853\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 16082\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 16082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 12115\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 12129\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 12129\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 3967\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 3953\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 3953\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 10795\n",
      "torgo_xlsr_finetune_F03 - Data Size: 6813\n",
      "torgo_xlsr_finetune_F04 - Data Size: 7482\n",
      "torgo_xlsr_finetune_M01 - Data Size: 4404\n",
      "torgo_xlsr_finetune_M02 - Data Size: 7687\n",
      "torgo_xlsr_finetune_M03 - Data Size: 7480\n",
      "torgo_xlsr_finetune_M04 - Data Size: 9139\n",
      "torgo_xlsr_finetune_M05 - Data Size: 7178\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 3614\n",
      "torgo_xlsr_finetune_F03 - Data Size: 1755\n",
      "torgo_xlsr_finetune_F04 - Data Size: 1972\n",
      "torgo_xlsr_finetune_M01 - Data Size: 2136\n",
      "torgo_xlsr_finetune_M02 - Data Size: 2103\n",
      "torgo_xlsr_finetune_M03 - Data Size: 2092\n",
      "torgo_xlsr_finetune_M04 - Data Size: 2612\n",
      "torgo_xlsr_finetune_M05 - Data Size: 1675\n",
      "      predictions references\n",
      "0             fee        fee\n",
      "2            knew       knew\n",
      "3            left       left\n",
      "4             air        air\n",
      "5            torn       torn\n",
      "...           ...        ...\n",
      "16075        must       nest\n",
      "16076       ruggd       ride\n",
      "16077         hem        him\n",
      "16079        sell       sell\n",
      "16080       spark      spark\n",
      "\n",
      "[12129 rows x 2 columns]\n",
      "      predictions references\n",
      "0           stick      stick\n",
      "1             pat        pat\n",
      "2              up         up\n",
      "3            meat       meat\n",
      "4              no       know\n",
      "...           ...        ...\n",
      "16073       witch      witch\n",
      "16076         nut        nut\n",
      "16077        sell       sell\n",
      "16080         sin        sin\n",
      "16081      victor     victor\n",
      "\n",
      "[12129 rows x 2 columns]\n",
      "      predictions references\n",
      "0           stick      stick\n",
      "1             pat        pat\n",
      "2              up         up\n",
      "3            meat       meat\n",
      "4              no       know\n",
      "...           ...        ...\n",
      "16075        nest       nest\n",
      "16076        rige       ride\n",
      "16077         hem        him\n",
      "16079         the       sell\n",
      "16080       spark      spark\n",
      "\n",
      "[12129 rows x 2 columns]\n",
      "      predictions references\n",
      "0           stick      stick\n",
      "1             pat        pat\n",
      "2              up         up\n",
      "3            meat       meat\n",
      "4             now       know\n",
      "...           ...        ...\n",
      "16075        must       nest\n",
      "16076        ride       ride\n",
      "16077         hem        him\n",
      "16079        selw       sell\n",
      "16080       spark      spark\n",
      "\n",
      "[12115 rows x 2 columns]\n",
      "      predictions references\n",
      "0           stick      stick\n",
      "1             pat        pat\n",
      "2              up         up\n",
      "3            meat       meat\n",
      "4              no       know\n",
      "...           ...        ...\n",
      "16075        nest       nest\n",
      "16076       rugge       ride\n",
      "16077         hem        him\n",
      "16079         sew       sell\n",
      "16080       spark      spark\n",
      "\n",
      "[12129 rows x 2 columns]\n",
      "      predictions references\n",
      "0           stick      stick\n",
      "1             pat        pat\n",
      "2              up         up\n",
      "3            meat       meat\n",
      "4              no       know\n",
      "...           ...        ...\n",
      "16075        must       nest\n",
      "16076         rug       ride\n",
      "16077         hem        him\n",
      "16079        sell       sell\n",
      "16080       spark      spark\n",
      "\n",
      "[12129 rows x 2 columns]\n",
      "      predictions references\n",
      "0           stick      stick\n",
      "1             pat        pat\n",
      "2              up         up\n",
      "3            meat       meat\n",
      "4              no       know\n",
      "...           ...        ...\n",
      "16075        must       nest\n",
      "16076         fge       ride\n",
      "16077         hem        him\n",
      "16079         sew       sell\n",
      "16080       spark      spark\n",
      "\n",
      "[12129 rows x 2 columns]\n",
      "      predictions references\n",
      "0           stick      stick\n",
      "1             pat        pat\n",
      "2              up         up\n",
      "3            meat       meat\n",
      "4            know       know\n",
      "...           ...        ...\n",
      "16075        must       nest\n",
      "16076        ride       ride\n",
      "16077         hem        him\n",
      "16079        sell       sell\n",
      "16080       spark      spark\n",
      "\n",
      "[12129 rows x 2 columns]\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 336\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 328\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 296\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 399\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 534\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 288\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 449\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 452\n",
      "\n",
      "torgo_xlsr_finetune_F01_keep_all - Data Size: 239\n",
      "torgo_xlsr_finetune_F03_keep_all - Data Size: 229\n",
      "torgo_xlsr_finetune_F04_keep_all - Data Size: 236\n",
      "torgo_xlsr_finetune_M01_keep_all - Data Size: 336\n",
      "torgo_xlsr_finetune_M02_keep_all - Data Size: 355\n",
      "torgo_xlsr_finetune_M03_keep_all - Data Size: 223\n",
      "torgo_xlsr_finetune_M04__keep_all - Data Size: 270\n",
      "torgo_xlsr_finetune_M05_keep_all - Data Size: 273\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 305\n",
      "torgo_xlsr_finetune_F03 - Data Size: 356\n",
      "torgo_xlsr_finetune_F04 - Data Size: 340\n",
      "torgo_xlsr_finetune_M01 - Data Size: 352\n",
      "torgo_xlsr_finetune_M02 - Data Size: 405\n",
      "torgo_xlsr_finetune_M03 - Data Size: 285\n",
      "torgo_xlsr_finetune_M04 - Data Size: 432\n",
      "torgo_xlsr_finetune_M05 - Data Size: 404\n",
      "\n",
      "torgo_xlsr_finetune_F01 - Data Size: 217\n",
      "torgo_xlsr_finetune_F03 - Data Size: 317\n",
      "torgo_xlsr_finetune_F04 - Data Size: 243\n",
      "torgo_xlsr_finetune_M01 - Data Size: 239\n",
      "torgo_xlsr_finetune_M02 - Data Size: 256\n",
      "torgo_xlsr_finetune_M03 - Data Size: 242\n",
      "torgo_xlsr_finetune_M04 - Data Size: 223\n",
      "torgo_xlsr_finetune_M05 - Data Size: 149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22904/2226408003.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word_df.drop(columns=['word_count'], inplace=True)\n",
      "/tmp/ipykernel_22904/2226408003.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sentence_df.drop(columns=['word_count'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "%run 01_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb86a76-1b1e-471c-91c7-a534e0b97ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3f926288a34ecab0dad776c5c682b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68605e94-a918-4e1e-b278-9a554f299cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torgo_xlsr_finetune_F01 - Data Size: 305\n",
      "torgo_xlsr_finetune_F03 - Data Size: 356\n",
      "torgo_xlsr_finetune_F04 - Data Size: 340\n",
      "torgo_xlsr_finetune_M01 - Data Size: 352\n",
      "torgo_xlsr_finetune_M02 - Data Size: 405\n",
      "torgo_xlsr_finetune_M03 - Data Size: 285\n",
      "torgo_xlsr_finetune_M04 - Data Size: 432\n",
      "torgo_xlsr_finetune_M05 - Data Size: 404\n"
     ]
    }
   ],
   "source": [
    "TORGO_TRAIN_TYPE=\"word_no_keep\"\n",
    "\n",
    "for df_name, df in dataframes_word_no_keep_all.items():\n",
    "    print(f\"{df_name} - Data Size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b05ff81-babf-45da-a4dd-89d36b509938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['references_phoneme', 'predictions_phoneme'],\n",
       "        num_rows: 233\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['references_phoneme', 'predictions_phoneme'],\n",
       "        num_rows: 26\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['references_phoneme', 'predictions_phoneme'],\n",
       "        num_rows: 31\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_datasets['F01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4707957-6037-4e8b-9aed-43f387116413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4d95677-9247-4ca4-a466-8123d3f4b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_speaker(speaker_id):\n",
    "    print(speaker_id)\n",
    "    # Apply preprocess_function to train_data and val_data\n",
    "    train_data=loaded_datasets[speaker_id]['train']\n",
    "    val_data=loaded_datasets[speaker_id]['valid']\n",
    "    train_data = train_data.map(preprocess_function, batched=True)\n",
    "    val_data = val_data.map(preprocess_function, batched=True)\n",
    "\n",
    "    # Prepare DataLoader for training and validation\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=16)\n",
    "\n",
    "    output_dir = f\"torgo_spell_correction_word_level_{speaker_id}\"\n",
    "\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        num_train_epochs=40,\n",
    "        predict_with_generate=True,\n",
    "        push_to_hub=True,\n",
    "        logging_steps=100\n",
    "    )\n",
    "\n",
    "    print(\"Train Dataset:\", train_data)\n",
    "    print(\"Validation Dataset:\", val_data)\n",
    "    print(\"Tokenizer:\", tokenizer)\n",
    "    print(\"Training Arguments:\", training_args)\n",
    "\n",
    "    model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # The Seq2SeqTrainer is created with the defined model, training arguments, datasets, tokenizer, and data_collator\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "# train_model_for_speaker('F01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95373961-8533-4316-b5a3-2154c1df7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_for_speaker('F03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "300cec6a-3f36-4cd8-b1f7-3cf2b710f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_for_speaker('F04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6992d3-bb61-497d-95cc-ad1177a264ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_for_speaker('M01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db03e7da-2d2d-4347-a81e-23eec88442dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_for_speaker('M02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74836218-e3a6-4300-b28e-97e2db6fb3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_for_speaker('M03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e9f78a2-f817-40fa-9f27-fc2dc49de0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_for_speaker('M04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb28318b-4c42-4f7b-8667-3ac785333504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_for_speaker('M05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "908b5d54-036d-43e5-a84a-461153e86af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74a3c0e32414700aa554e312b7c6f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4d30a469314134982ae1dabc7be9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1b9d529ac24cc984e5cb48853c365c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d84e2ac5f548cdb3cf9237c13ebe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49517471afa14874b38793ad55890f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d307750af97c4dc092e089711753ba6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bddbb0f03814807850f4e0f2c52ddb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e94fe4500742c7884b3cc0ddfad6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed03bc4e25a4d7c9ac6365c2de07893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ae45e9b66b4c1d8ce8856b391854a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb65c5817bbe48f6b200cada51686f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62860182402d495991631619b974136f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198e6a04804d49899761d373827355cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9845ed71b24f6cbf215987288eddc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424348919819417388c507cf61932383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09aa6ab3aea34aa89b23d12e2f534d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "SPEAKERS = ['F01', 'F03', 'F04', 'M01', 'M02', 'M03', 'M04', 'M05']\n",
    "models = {}\n",
    "\n",
    "for speaker in SPEAKERS:\n",
    "    model_name = f\"matrixcc/torgo_spell_correction_word_level_{speaker}\"\n",
    "    models[speaker] = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91f87b87-3ead-4296-82e2-04c6b0bf2ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/van-speech-nlp/jindaznb/asrenv/lib/python3.10/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for speaker, model in models.items():\n",
    "    models[speaker] = model.to(device)\n",
    "    models[speaker].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fad3b362-dd10-4e1d-a443-d0e63c59af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_speaker(model, tokenizer, speaker_id):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    test_dataset = loaded_datasets[speaker_id]['test']\n",
    "    test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "    model.eval()\n",
    "\n",
    "    for example in test_dataset:\n",
    "        input_text = f\"{example['predictions_phoneme']}\"\n",
    "        with torch.no_grad():\n",
    "            input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "            outputs = model.generate(input_ids=input_ids, max_length=max_length)\n",
    "\n",
    "        predicted_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "        references.append(example['references_phoneme'])\n",
    "        predictions.append(predicted_sentence)\n",
    "\n",
    "    # Verify that the number of predictions and references are the same\n",
    "    if len(predictions) == len(references):\n",
    "        print(\"Number of predictions and references are the same.\")\n",
    "    else:\n",
    "        print(\"Mismatch in the number of predictions and references.\")\n",
    "\n",
    "    # Print the number of predictions and references\n",
    "    print(\"Number of predictions:\", len(predictions))\n",
    "    print(\"Number of references:\", len(references))\n",
    "    # print the length of the dataset\n",
    "    print(\"Number of rows in dataset:\", len(test_dataset))\n",
    "\n",
    "    # Assuming 'predictions' and 'references' are your sequences\n",
    "    # Calculate Word Error Rate (WER)\n",
    "    wer_value = wer(predictions, references)\n",
    "    wer_percentage = wer_value * 100\n",
    "    print(f\"WER for {speaker_id}: {wer_percentage:.2f}%\")\n",
    "\n",
    "    # Calculate Character Error Rate (CER)\n",
    "    cer_value = cer(predictions, references)\n",
    "    cer_percentage = cer_value * 100\n",
    "    print(f\"CER for {speaker_id}: {cer_percentage:.2f}%\")\n",
    "\n",
    "    # Save predictions for the speaker\n",
    "    predictions_dict[speaker_id] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82dadfaf-adb3-4d02-87e6-cae7dcba3abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions and references are the same.\n",
      "Number of predictions: 31\n",
      "Number of references: 31\n",
      "Number of rows in dataset: 31\n",
      "WER for F01: 58.42%\n",
      "CER for F01: 41.32%\n",
      "Number of predictions and references are the same.\n",
      "Number of predictions: 36\n",
      "Number of references: 36\n",
      "Number of rows in dataset: 36\n",
      "WER for F03: 49.23%\n",
      "CER for F03: 33.12%\n",
      "Number of predictions and references are the same.\n",
      "Number of predictions: 34\n",
      "Number of references: 34\n",
      "Number of rows in dataset: 34\n",
      "WER for F04: 38.05%\n",
      "CER for F04: 25.90%\n",
      "Number of predictions and references are the same.\n",
      "Number of predictions: 36\n",
      "Number of references: 36\n",
      "Number of rows in dataset: 36\n",
      "WER for M01: 44.63%\n",
      "CER for M01: 33.56%\n",
      "Number of predictions and references are the same.\n",
      "Number of predictions: 41\n",
      "Number of references: 41\n",
      "Number of rows in dataset: 41\n",
      "WER for M02: 69.72%\n",
      "CER for M02: 51.17%\n",
      "Number of predictions and references are the same.\n",
      "Number of predictions: 29\n",
      "Number of references: 29\n",
      "Number of rows in dataset: 29\n",
      "WER for M03: 44.86%\n",
      "CER for M03: 30.27%\n",
      "Number of predictions and references are the same.\n",
      "Number of predictions: 44\n",
      "Number of references: 44\n",
      "Number of rows in dataset: 44\n",
      "WER for M04: 64.14%\n",
      "CER for M04: 44.66%\n",
      "Number of predictions and references are the same.\n",
      "Number of predictions: 41\n",
      "Number of references: 41\n",
      "Number of rows in dataset: 41\n",
      "WER for M05: 55.48%\n",
      "CER for M05: 37.64%\n"
     ]
    }
   ],
   "source": [
    "predictions_dict = {}\n",
    "for speaker_id, model in models.items():\n",
    "    evaluate_speaker(model, tokenizer, speaker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f8409a6-3345-466d-b375-c5d767398d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S P R IH1 T',\n",
       " 'R AH1 T',\n",
       " 'TH R IY1',\n",
       " 'T EH1 N',\n",
       " 'TH IY1',\n",
       " 'CH EY1 S',\n",
       " 'TH R IY1',\n",
       " 'S W EY1 N',\n",
       " 'S IY1',\n",
       " 'L IH1 P',\n",
       " 'R AY1 T',\n",
       " 'M AH1 G',\n",
       " 'R IH1 T',\n",
       " 'B R AO1 N',\n",
       " 'F UW1 T',\n",
       " 'HH AE1 T',\n",
       " 'P AA1 R',\n",
       " 'L IY1 G',\n",
       " 'S EH1 L',\n",
       " 'B R AO1 T',\n",
       " 'F AO1 R K S',\n",
       " 'S AY1 N',\n",
       " 'K AE1 S',\n",
       " 'B UH1 K',\n",
       " 'M UW1',\n",
       " 'AO1 L S OW0',\n",
       " 'P R AW1 T',\n",
       " 'G AH1 M AH0 L',\n",
       " 'EH1 M B',\n",
       " 'R IH1 G T',\n",
       " 'T IY1']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dict['F01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a6cb1-09ba-480a-a87b-714a6205a326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
