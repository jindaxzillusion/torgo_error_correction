{
  "evaluation_strategy": "steps",
  "per_device_train_batch_size": 4,
  "per_device_eval_batch_size": 4,
  "gradient_accumulation_steps": 2,
  "eval_delay": 0,
  "learning_rate": 0.0001,
  "weight_decay": 0.005,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "adam_epsilon": 1e-8,
  "max_grad_norm": 1.0,
  "max_steps": -1,
  "lr_scheduler_type": "linear",
  "warmup_ratio": 0.0,
  "warmup_steps": 1000,
  "save_strategy": "steps",
  "save_steps": 500,
  "save_total_limit": 3,
  "report_to": "all",
  "seed": 42,
  "eval_steps": 1000,
  "num_train_epochs": 20,
  "optim": "adamw_torch",
  "optim_args": null,
  "adafactor": false,
  "group_by_length": true,
  "length_column_name": "length",
  "push_to_hub": true,
  "hub_strategy": "every_save"
}
