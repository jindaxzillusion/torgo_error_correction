{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/torch/cuda/__init__.py:740: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "%run 10_kenlm_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#from g2p_en import G2p\n",
    "from g2p import make_g2p\n",
    "from num2words import num2words  # Import num2words from nltk\n",
    "import re\n",
    "\n",
    "# Load the Tatoeba dataset\n",
    "tatoeba_dataset = load_dataset(\"tatoeba\", 'en-mr')\n",
    "\n",
    "# Initialize g2p converter\n",
    "transducer = make_g2p('eng', 'eng-arpabet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = tatoeba_dataset[\"train\"][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoneme Vocabulary:\n",
      "{'UW', 'NG', 'HH', 'AY', 'EY', 'W', 'M', 'F', 'R', 'N', 'T', 'G', ',,', ',', 'ER', 'Z', 'AW', 'SH', 'D', 'AA', 'Y', 'ZH', 'JH', 'EH', 'AO', 'L', 'K', 'TH', ',,,', 'AE', 'IY', 'OW', 'OY', 'S', 'B', 'DH', 'UH', 'V', 'P', 'CH', 'AH', 'IH'}\n"
     ]
    }
   ],
   "source": [
    "unique_phonemes = set()\n",
    "\n",
    "with open(\"dataset_phonemes.txt\", \"w\") as file:\n",
    "    for translation in translations:\n",
    "      sentence = translation[\"en\"]\n",
    "      sentence = remove_punctuation_and_special_characters(sentence)\n",
    "      sentence = convert_numbers_to_words(sentence)\n",
    "      phonemes_list = [transducer(word).output_string for word in re.findall(r'\\S+', sentence)]\n",
    "      all_phonemes = [item for sublist in phonemes_list for item in sublist.split()]\n",
    "\n",
    "      # Update the set of unique phonemes excluding those containing hyphens\n",
    "      unique_phonemes.update(phoneme for phoneme in all_phonemes if \"-\" not in phoneme)\n",
    "\n",
    "      # Replace hyphens with letters that come after the hyphen\n",
    "      all_phonemes_no_hyphen = [phoneme.split(\"-\")[-1] if \"-\" in phoneme else phoneme for phoneme in all_phonemes]\n",
    "\n",
    "      # Write all individual phonemes (without hyphens) to the file\n",
    "      file.write(\" \".join(all_phonemes_no_hyphen))\n",
    "      file.write(\"\\n\")\n",
    "\n",
    "# Print the vocabulary of phonemes\n",
    "print(\"Phoneme Vocabulary:\")\n",
    "print(unique_phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates while preserving the order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content from the file\n",
    "with open(\"dataset_phonemes.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Remove instances of consecutive triple commas (,,,)\n",
    "content = content.replace(',,,', '')\n",
    "\n",
    "# Remove instances of consecutive double commas (,,)\n",
    "content = content.replace(',,', '')\n",
    "\n",
    "# Remove individual commas\n",
    "content = content.replace(',', '')\n",
    "# Write the modified content back to the file\n",
    "with open('dataset_phonemes.txt', 'w') as file:\n",
    "    file.write(content)\n",
    "    \n",
    "from collections import OrderedDict\n",
    "\n",
    "# Read the content from the file\n",
    "with open(\"dataset_phonemes.txt\", 'r') as file:\n",
    "    content = file.readlines()\n",
    "\n",
    "# Remove duplicates while preserving the order\n",
    "unique_content = list(OrderedDict.fromkeys(content))\n",
    "\n",
    "# Write the modified content back to the file\n",
    "with open('dataset_phonemes.txt', 'w') as file:\n",
    "    file.writelines(unique_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
