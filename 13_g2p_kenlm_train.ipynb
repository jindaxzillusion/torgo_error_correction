{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914ca930-3fb1-458e-b55e-1ae4fd93127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/osx/anaconda3/envs/aac/lib/python3.10/site-packages/torch/cuda/__init__.py:740: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "%run 10_kenlm_common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dfba4b-1a68-4559-bcf7-950a8e892d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_dataset = \"dataset_phonemes.txt\"\n",
    "output_directory = \"output_directory/\"\n",
    "output_model_base = \"output_model.klm\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Ngram size options\n",
    "order_trigram = 3\n",
    "order_unigram = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e73e5-f66c-40ac-aa13-074e227de0c4",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66226b3-3c5c-478b-b7a7-a382f8a05a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/osx/Documents/research/slang-ra/torgo_inference_on_cluster/JamSpell/build/kenlm/util/file.cc:76 in int util::OpenReadOrThrow(const char*) threw ErrnoException because `-1 == (ret = open(name, 00))'.\n",
      "No such file or directory while opening output_directory/output_model.klm_trigram.arpa\n",
      "ERROR\n",
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /home/osx/Documents/research/slang-ra/torgo_inference_on_cluster/dataset_phonemes.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Unigram tokens 635344 types 42\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:504 2:10482238464 3:19654197248\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\n",
      "Statistics:\n",
      "1 42 D1=0.5 D2=1 D3+=1.5\n",
      "2 1280 D1=0.420074 D2=0.998284 D3+=1.12999\n",
      "3 16435 D1=0.483725 D2=1.009 D3+=1.52672\n",
      "Memory estimate for binary LM:\n",
      "type     kB\n",
      "probing 319 assuming -p 1.5\n",
      "probing 327 assuming -r models -p 1.5\n",
      "trie     88 without quantization\n",
      "trie     37 assuming -q 8 -b 8 quantization \n",
      "trie     87 assuming -a 22 array pointer compression\n",
      "trie     37 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:504 2:20480 3:328700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:504 2:20480 3:328700\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:29578364 kB\tVmRSS:6260 kB\tRSSMax:6791756 kB\tuser:0.379488\tsys:1.73766\tCPU:2.11717\treal:2.12043\n"
     ]
    }
   ],
   "source": [
    "!kenlm/build/bin/lmplz -o 3    --text dataset_phonemes.txt     --arpa output_directory/output_model.klm_trigram.arpa     --discount_fallback --skip_symbols|     kenlm/build/bin/build_binary     -T /dev/stdin output_directory/output_model.klm_trigram.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d535394e-8b6d-4a0d-ba09-5a195fbd0f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading output_directory/output_model.klm_trigram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!kenlm/build/bin/build_binary\\\n",
    "    output_directory/output_model.klm_trigram.arpa \\\n",
    "    output_directory/output_model.klm_trigram.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d05e0b-b5f4-4624-a685-d99b507e0cad",
   "metadata": {},
   "source": [
    "# compress model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f1ac4d-81e7-4f47-bd40-eb18540eff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading output_directory/output_model.klm_trigram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!kenlm/build/bin/build_binary\\\n",
    "    output_directory/output_model.klm_trigram.arpa \\\n",
    "    output_directory/output_model.klm_trigram.klm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4202fad-c53f-4b09-827d-5823e571feb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'3=16435', '1=42', '2=1280'}\n",
      "Vocabulary: {'3=16435', '1=42', '2=1280'}\n"
     ]
    }
   ],
   "source": [
    "arpa_path = \"output_directory/output_model.klm_trigram.arpa\"\n",
    "vocabulary = get_vocabulary_from_arpa(arpa_path)\n",
    "# Print or use the vocabulary as needed\n",
    "print(\"Vocabulary:\", vocabulary)\n",
    "# Tokens to add\n",
    "new_tokens = [\"<pad>\", \"<sil>\", \"<spn>\"]\n",
    "# Tokens to exclude\n",
    "tokens_to_exclude = [\"<s>\", \"</s>\"]\n",
    "# Add tokens to the ARPA file excluding the specified tokens\n",
    "add_tokens_to_arpa(arpa_path, new_tokens, tokens_to_exclude)\n",
    "vocabulary = get_vocabulary_from_arpa(arpa_path)\n",
    "\n",
    "# Print or use the vocabulary as needed\n",
    "print(\"Vocabulary:\", vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92489022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_common.ipynb\t\t  11_prepare_torgo_dataset.ipynb  output_directory\n",
      "01_prepare_dataset.ipynb  12_prepare_kenlm_data.ipynb\t  results\n",
      "01_preprocess.ipynb\t  13_g2p_kenlm_train.ipynb\t  torgo.csv\n",
      "02_bart_no_keep.ipynb\t  data\t\t\t\t  training_args.json\n",
      "02_save_dataset.ipynb\t  dataset_phonemes.txt\t\t  train.py\n",
      "03_bart_keep-all.ipynb\t  JamSpell\t\t\t  Untitled.ipynb\n",
      "03_bart_keep.ipynb\t  kenlm\t\t\t\t  vocab\n",
      "10_kenlm_common.ipynb\t  logs\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79cf5ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/osx/Documents/research/slang-ra/torgo_inference_on_cluster/JamSpell/build\n"
     ]
    }
   ],
   "source": [
    "%cd JamSpell\n",
    "%cd build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c1bc8",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2279e63e-51fe-407d-82e7-1cb213e28fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] loading text\n",
      "[info] generating N-grams 1\n",
      "[info] generating keys\n",
      "[info] ngrams1: 39\n",
      "[info] ngrams2: 1228\n",
      "[info] ngrams3: 17135\n",
      "[info] total: 18402\n",
      "[info] generating perf hash\n",
      "[info] finished, buckets: 23003\n",
      "[info] buckets filled\n"
     ]
    }
   ],
   "source": [
    "!./main/jamspell train ../test_data/alphabet_en.txt ../test_data/dataset_phonemes.txt model_torgo.bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88a5eeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/osx/Documents/research/slang-ra/torgo_inference_on_cluster/JamSpell/build\n",
      "CMakeCache.txt\tcmake_install.cmake  jamspell  Makefile\t\ttests\n",
      "CMakeFiles\tcontrib\t\t     main      model_torgo.bin\tweb_server\n"
     ]
    }
   ],
   "source": [
    "%cd build\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ee6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/osx/Documents/research/slang-ra/torgo_inference_on_cluster/JamSpell/build/../evaluate/evaluate.py\", line 14, in <module>\n",
      "    from evaluate import typo_model\n",
      "  File \"/home/osx/Documents/research/slang-ra/torgo_inference_on_cluster/JamSpell/evaluate/evaluate.py\", line 14, in <module>\n",
      "    from evaluate import typo_model\n",
      "ImportError: cannot import name 'typo_model' from partially initialized module 'evaluate' (most likely due to a circular import) (/home/osx/Documents/research/slang-ra/torgo_inference_on_cluster/JamSpell/evaluate/evaluate.py)\n"
     ]
    }
   ],
   "source": [
    "!python ../evaluate/evaluate.py\\\n",
    "\t -a ../test_data/alphabet_en.txt\\\n",
    "\t -jsp model_torgo.bin\\\n",
    "\t -mx 50000 ../test_data/dataset_phonemes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74c9095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T AH D EY IH Z JH UW N AH N D IH T IH Z B ER TH D EY'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jamspell\n",
    "\n",
    "corrector = jamspell.TSpellCorrector()\n",
    "corrector.LoadLangModel('model_torgo.bin')\n",
    "\n",
    "corrector.FixFragment('T AH D EY IH Z JH UW N AH N D IH T IH Z B ER TH D EQ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46e400d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
